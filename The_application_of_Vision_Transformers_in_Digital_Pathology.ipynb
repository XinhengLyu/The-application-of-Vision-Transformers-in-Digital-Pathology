{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/XinhengLyu/The-application-of-Vision-Transformers-in-Digital-Pathology/blob/main/The_application_of_Vision_Transformers_in_Digital_Pathology.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_WsVEZHeRDR"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-OQOLkeQcmJ6"
      },
      "outputs": [],
      "source": [
        "!pip install optuna==2.10.1\n",
        "!pip install torch-cka"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6AsvfOaEKBC"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "import pandas as pd\n",
        "import time\n",
        "import os\n",
        "import math\n",
        "import argparse\n",
        "import torch.optim as optim\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchvision import transforms\n",
        "from torchvision.models.resnet import ResNet, BasicBlock\n",
        "import sys\n",
        "import json\n",
        "import pickle\n",
        "import random\n",
        "from functools import partial\n",
        "from collections import OrderedDict\n",
        "from tqdm import tqdm\n",
        "import optuna\n",
        "import logging\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpKNjpiXL8LS"
      },
      "source": [
        "# Model and Method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJseRZw9aRUt"
      },
      "source": [
        "## ViT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWQYdSL8WrGX"
      },
      "outputs": [],
      "source": [
        "def drop_path(x, drop_prob: float = 0., training: bool = False):\n",
        "\n",
        "    if drop_prob == 0. or not training:\n",
        "        return x\n",
        "    keep_prob = 1 - drop_prob\n",
        "    shape = (x.shape[0],) + (1,) * (x.ndim - 1)  # work with diff dim tensors, not just 2D ConvNets\n",
        "    random_tensor = keep_prob + torch.rand(shape, dtype=x.dtype, device=x.device)\n",
        "    random_tensor.floor_()  # binarize\n",
        "    output = x.div(keep_prob) * random_tensor\n",
        "    return output\n",
        "\n",
        "\n",
        "class DropPath(nn.Module):\n",
        "    \"\"\"\n",
        "    Drop paths (Stochastic Depth) per sample  (when applied in main path of residual blocks).\n",
        "    \"\"\"\n",
        "    def __init__(self, drop_prob=None):\n",
        "        super(DropPath, self).__init__()\n",
        "        self.drop_prob = drop_prob\n",
        "\n",
        "    def forward(self, x):\n",
        "        return drop_path(x, self.drop_prob, self.training)\n",
        "\n",
        "\n",
        "class PatchEmbed(nn.Module):\n",
        "\n",
        "    def __init__(self, img_size=224, patch_size=16, in_c=3, embed_dim=768, norm_layer=None):\n",
        "        super().__init__()\n",
        "        img_size = (img_size, img_size)\n",
        "        patch_size = (patch_size, patch_size)\n",
        "        self.img_size = img_size\n",
        "        self.patch_size = patch_size\n",
        "        self.grid_size = (img_size[0] // patch_size[0], img_size[1] // patch_size[1])\n",
        "        self.num_patches = self.grid_size[0] * self.grid_size[1]\n",
        "\n",
        "        self.proj = nn.Conv2d(in_c, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
        "        self.norm = norm_layer(embed_dim) if norm_layer else nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, C, H, W = x.shape\n",
        "        assert H == self.img_size[0] and W == self.img_size[1], \\\n",
        "            f\"Input image size ({H}*{W}) doesn't match model ({self.img_size[0]}*{self.img_size[1]}).\"\n",
        "\n",
        "        # flatten: [B, C, H, W] -> [B, C, HW]\n",
        "        # transpose: [B, C, HW] -> [B, HW, C]\n",
        "        x = self.proj(x).flatten(2).transpose(1, 2)\n",
        "        x = self.norm(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self,\n",
        "                 dim,  \n",
        "                 num_heads=8,\n",
        "                 qkv_bias=False,\n",
        "                 qk_scale=None,\n",
        "                 attn_drop_ratio=0.,\n",
        "                 proj_drop_ratio=0.):\n",
        "        super(Attention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = dim // num_heads\n",
        "        self.scale = qk_scale or head_dim ** -0.5\n",
        "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
        "        self.attn_drop = nn.Dropout(attn_drop_ratio)\n",
        "        self.proj = nn.Linear(dim, dim)\n",
        "        self.proj_drop = nn.Dropout(proj_drop_ratio)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # [batch_size, num_patches + 1, total_embed_dim]\n",
        "        B, N, C = x.shape\n",
        "\n",
        "        # qkv(): -> [batch_size, num_patches + 1, 3 * total_embed_dim]\n",
        "        # reshape: -> [batch_size, num_patches + 1, 3, num_heads, embed_dim_per_head]\n",
        "        # permute: -> [3, batch_size, num_heads, num_patches + 1, embed_dim_per_head]\n",
        "        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
        "        # [batch_size, num_heads, num_patches + 1, embed_dim_per_head]\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2]  # make torchscript happy (cannot use tensor as tuple)\n",
        "\n",
        "        # transpose: -> [batch_size, num_heads, embed_dim_per_head, num_patches + 1]\n",
        "        # @: multiply -> [batch_size, num_heads, num_patches + 1, num_patches + 1]\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
        "        attn = attn.softmax(dim=-1)\n",
        "        attn = self.attn_drop(attn)\n",
        "\n",
        "        # @: multiply -> [batch_size, num_heads, num_patches + 1, embed_dim_per_head]\n",
        "        # transpose: -> [batch_size, num_patches + 1, num_heads, embed_dim_per_head]\n",
        "        # reshape: -> [batch_size, num_patches + 1, total_embed_dim]\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "        x = self.proj(x)\n",
        "        x = self.proj_drop(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Mlp(nn.Module):\n",
        "    \"\"\"\n",
        "    MLP as used in Vision Transformer, MLP-Mixer and related networks\n",
        "    \"\"\"\n",
        "    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n",
        "\n",
        "        super().__init__()\n",
        "        out_features = out_features or in_features\n",
        "        hidden_features = hidden_features or in_features\n",
        "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
        "        self.act = act_layer()\n",
        "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
        "        self.drop = nn.Dropout(drop)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.drop(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self,\n",
        "                 dim,\n",
        "                 num_heads,\n",
        "                 mlp_ratio=4.,\n",
        "                 qkv_bias=False,\n",
        "                 qk_scale=None,\n",
        "                 drop_ratio=0.,\n",
        "                 attn_drop_ratio=0.,\n",
        "                 drop_path_ratio=0.,\n",
        "                 act_layer=nn.GELU,\n",
        "                 norm_layer=nn.LayerNorm):\n",
        "        super(Block, self).__init__()\n",
        "        self.norm1 = norm_layer(dim)\n",
        "        self.attn = Attention(dim, num_heads=num_heads, qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
        "                              attn_drop_ratio=attn_drop_ratio, proj_drop_ratio=drop_ratio)\n",
        "        # NOTE: drop path for stochastic depth, we shall see if this is better than dropout here\n",
        "        self.drop_path = DropPath(drop_path_ratio) if drop_path_ratio > 0. else nn.Identity()\n",
        "        self.norm2 = norm_layer(dim)\n",
        "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
        "        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop_ratio)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.drop_path(self.attn(self.norm1(x)))\n",
        "        x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
        "        return x\n",
        "\n",
        "\n",
        "class VisionTransformer(nn.Module):\n",
        "    def __init__(self, img_size=224, patch_size=16, in_c=3, num_classes=1000,\n",
        "                 embed_dim=768, depth=12, num_heads=12, mlp_ratio=4.0, qkv_bias=True,\n",
        "                 qk_scale=None, representation_size=None, distilled=False, drop_ratio=0.,\n",
        "                 attn_drop_ratio=0., drop_path_ratio=0., embed_layer=PatchEmbed, norm_layer=None,\n",
        "                 act_layer=None):\n",
        "\n",
        "        super(VisionTransformer, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.in_c=in_c\n",
        "        self.img_size=img_size\n",
        "        self.num_features = self.embed_dim = embed_dim  # num_features for consistency with other models\n",
        "        self.num_tokens = 2 if distilled else 1\n",
        "        norm_layer = norm_layer or partial(nn.LayerNorm, eps=1e-6)\n",
        "        act_layer = act_layer or nn.GELU\n",
        "\n",
        "        self.patch_embed = embed_layer(img_size=img_size, patch_size=patch_size, in_c=in_c, embed_dim=embed_dim)\n",
        "        num_patches = self.patch_embed.num_patches\n",
        "\n",
        "        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
        "        self.dist_token = nn.Parameter(torch.zeros(1, 1, embed_dim)) if distilled else None\n",
        "        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches + self.num_tokens, embed_dim))\n",
        "        self.pos_drop = nn.Dropout(p=drop_ratio)\n",
        "\n",
        "        dpr = [x.item() for x in torch.linspace(0, drop_path_ratio, depth)]  # stochastic depth decay rule\n",
        "        self.blocks = nn.Sequential(*[\n",
        "            Block(dim=embed_dim, num_heads=num_heads, mlp_ratio=mlp_ratio, qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
        "                  drop_ratio=drop_ratio, attn_drop_ratio=attn_drop_ratio, drop_path_ratio=dpr[i],\n",
        "                  norm_layer=norm_layer, act_layer=act_layer)\n",
        "            for i in range(depth)\n",
        "        ])\n",
        "        self.norm = norm_layer(embed_dim)\n",
        "\n",
        "        # Representation layer\n",
        "        if representation_size and not distilled:\n",
        "            self.has_logits = True\n",
        "            self.num_features = representation_size\n",
        "            self.pre_logits = nn.Sequential(OrderedDict([\n",
        "                (\"fc\", nn.Linear(embed_dim, representation_size)),\n",
        "                (\"act\", nn.Tanh())\n",
        "            ]))\n",
        "        else:\n",
        "            self.has_logits = False\n",
        "            self.pre_logits = nn.Identity()\n",
        "\n",
        "        # Classifier head(s)\n",
        "        self.head = nn.Linear(self.num_features, num_classes) if num_classes > 0 else nn.Identity()\n",
        "        self.head_dist = None\n",
        "        if distilled:\n",
        "            self.head_dist = nn.Linear(self.embed_dim, self.num_classes) if num_classes > 0 else nn.Identity()\n",
        "\n",
        "        # Weight init\n",
        "        nn.init.trunc_normal_(self.pos_embed, std=0.02)\n",
        "        if self.dist_token is not None:\n",
        "            nn.init.trunc_normal_(self.dist_token, std=0.02)\n",
        "\n",
        "        nn.init.trunc_normal_(self.cls_token, std=0.02)\n",
        "        self.apply(_init_vit_weights)\n",
        "\n",
        "    def forward_features(self, x):\n",
        "        # [B, C, H, W] -> [B, num_patches, embed_dim]\n",
        "        x = self.patch_embed(x)  # [B, 196, 768]\n",
        "        # [1, 1, 768] -> [B, 1, 768]\n",
        "        cls_token = self.cls_token.expand(x.shape[0], -1, -1)\n",
        "        if self.dist_token is None:\n",
        "            x = torch.cat((cls_token, x), dim=1)  # [B, 197, 768]\n",
        "        else:\n",
        "            x = torch.cat((cls_token, self.dist_token.expand(x.shape[0], -1, -1), x), dim=1)\n",
        "\n",
        "        x = self.pos_drop(x + self.pos_embed)\n",
        "        x = self.blocks(x)\n",
        "        x = self.norm(x)\n",
        "        if self.dist_token is None:\n",
        "            return self.pre_logits(x[:, 0])\n",
        "        else:\n",
        "            return x[:, 0], x[:, 1]\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.forward_features(x)\n",
        "        if self.head_dist is not None:\n",
        "            x, x_dist = self.head(x[0]), self.head_dist(x[1])\n",
        "            if self.training and not torch.jit.is_scripting():\n",
        "                # during inference, return the average of both classifier predictions\n",
        "                return x, x_dist\n",
        "            else:\n",
        "                return (x + x_dist) / 2\n",
        "        else:\n",
        "            x = self.head(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def _init_vit_weights(m):\n",
        "    \"\"\"\n",
        "    ViT weight initialization\n",
        "    :param m: module\n",
        "    \"\"\"\n",
        "    if isinstance(m, nn.Linear):\n",
        "        nn.init.trunc_normal_(m.weight, std=.01)\n",
        "        if m.bias is not None:\n",
        "            nn.init.zeros_(m.bias)\n",
        "    elif isinstance(m, nn.Conv2d):\n",
        "        nn.init.kaiming_normal_(m.weight, mode=\"fan_out\")\n",
        "        if m.bias is not None:\n",
        "            nn.init.zeros_(m.bias)\n",
        "    elif isinstance(m, nn.LayerNorm):\n",
        "        nn.init.zeros_(m.bias)\n",
        "        nn.init.ones_(m.weight)\n",
        "\n",
        "\n",
        "def ViT(img_size:int=224,num_classes: int = 1000,patch_size: int =16,embed_dim: int=768,depth: int=12,num_heads: int=12,in_c:int=3):\n",
        "\n",
        "    model = VisionTransformer(img_size=img_size,\n",
        "                              patch_size=patch_size,\n",
        "                              embed_dim=embed_dim,\n",
        "                              depth=depth,\n",
        "                              num_heads=num_heads,\n",
        "                              representation_size=None,\n",
        "                              in_c=in_c,\n",
        "                              num_classes=num_classes)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJBLEyzubPwe"
      },
      "source": [
        "## Train and Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYX4TJ8-QIJe"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, optimizer, data_loader, device, epoch):\n",
        "    model.train()\n",
        "    loss_function = torch.nn.CrossEntropyLoss()\n",
        "    accu_loss = torch.zeros(1).to(device)\n",
        "    accu_num = torch.zeros(1).to(device)\n",
        "    optimizer.zero_grad()\n",
        "    sample_num = 0\n",
        "    data_loader = tqdm(data_loader, file=sys.stdout)\n",
        "    for step, data in enumerate(data_loader):\n",
        "        images, labels = data\n",
        "        sample_num += images.shape[0]\n",
        "\n",
        "        pred = model(images.to(device))\n",
        "        pred_classes = torch.max(pred, dim=1)[1]\n",
        "        accu_num += torch.eq(pred_classes, labels.to(device)).sum()\n",
        "\n",
        "        loss = loss_function(pred, labels.to(device))\n",
        "        # train_loss.append(loss.cpu().item())\n",
        "        loss.backward()\n",
        "        accu_loss += loss.detach()\n",
        "\n",
        "        data_loader.desc = \"[train epoch {}] loss: {:.3f}, acc: {:.3f}\".format(epoch,\n",
        "                                                                               accu_loss.item() / (step + 1),\n",
        "                                                                               accu_num.item() / sample_num)\n",
        "\n",
        "        if not torch.isfinite(loss):\n",
        "            print('WARNING: non-finite loss, ending training ', loss)\n",
        "            sys.exit(1)\n",
        "\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    return accu_loss.item() / (step + 1), accu_num.item() / sample_num\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, data_loader, device, epoch):\n",
        "    loss_function = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    accu_num = torch.zeros(1).to(device)   \n",
        "    accu_loss = torch.zeros(1).to(device) \n",
        "   \n",
        "    sample_num = 0\n",
        "    data_loader = tqdm(data_loader, file=sys.stdout)\n",
        "    for step, data in enumerate(data_loader):\n",
        "        images, labels = data\n",
        "        sample_num += images.shape[0]\n",
        "\n",
        "        pred = model(images.to(device))\n",
        "        pred_classes = torch.max(pred, dim=1)[1]\n",
        "        accu_num += torch.eq(pred_classes, labels.to(device)).sum()\n",
        "\n",
        "        loss = loss_function(pred, labels.to(device))\n",
        "        accu_loss += loss\n",
        "\n",
        "        data_loader.desc = \"[valid epoch {}] loss: {:.3f}, acc: {:.3f}\".format(epoch,\n",
        "                                                                               accu_loss.item() / (step + 1),\n",
        "                                                                               accu_num.item() / sample_num)\n",
        "\n",
        "    return accu_loss.item() / (step + 1), accu_num.item() / sample_num"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUkpSvijdAOv"
      },
      "source": [
        "## ResNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ToVPLrPBc-oS"
      },
      "outputs": [],
      "source": [
        "class MyResNet(ResNet):\n",
        "    def __init__(self):\n",
        "        super(MyResNet, self).__init__(BasicBlock, [2,2,1,1], num_classes=10)\n",
        "        self.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return torch.softmax(super(MyResNet, self).forward(x), dim=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsTkNskKEZ75"
      },
      "source": [
        "# Mnist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2JBOFywsfDk"
      },
      "source": [
        "## Get Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q58MsHI2OItZ"
      },
      "outputs": [],
      "source": [
        "Mnist_batch_size = 128\n",
        "Mnist_transform = transforms.Compose([transforms.ToTensor()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JY44fqqSElpr"
      },
      "outputs": [],
      "source": [
        "Mnist_DOWNLOAD_PATH = './'\n",
        "\n",
        "Mnist_train_set = torchvision.datasets.MNIST(Mnist_DOWNLOAD_PATH, train=True, download=True,\n",
        "                                       transform=Mnist_transform)\n",
        "Mnist_train_loader = torch.utils.data.DataLoader(Mnist_train_set,batch_size=Mnist_batch_size,shuffle=True,num_workers=4)\n",
        "\n",
        "Mnist_test_set = torchvision.datasets.MNIST(Mnist_DOWNLOAD_PATH, train=False, download=True,\n",
        "                                      transform=Mnist_transform)\n",
        "Mnist_test_loader = torch.utils.data.DataLoader(Mnist_test_set,batch_size=Mnist_batch_size,shuffle=False,num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWRnZD67NYSq"
      },
      "outputs": [],
      "source": [
        "images, labels = next(iter(Mnist_train_loader))\n",
        "print(images.size())\n",
        "plt.figure(figsize=(9, 9))\n",
        "for i in range(10):\n",
        "    plt.subplot(1, 10, i+1)\n",
        "    plt.title(labels[i].item())\n",
        "    img=images[i].permute(1, 2, 0)\n",
        "    plt.imshow(torch.squeeze(img, dim=2), cmap='gray')\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSfG9ECatCNp"
      },
      "source": [
        "## Train-ViT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hOh786jSsbgE"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(4)\n",
        "epochs=20\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "tb_writer = SummaryWriter()\n",
        "\n",
        "MNIST_ViT_model = ViT(img_size=28,num_classes=10,patch_size=7,embed_dim=64,depth=3,num_heads=8,in_c=1).to(device)\n",
        "\n",
        "optimizer = optim.Adam(MNIST_ViT_model.parameters(), lr=0.0003)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # train\n",
        "    train_loss, train_acc= train_one_epoch(model=MNIST_ViT_model,\n",
        "                                            optimizer=optimizer,\n",
        "                                            data_loader=Mnist_train_loader,\n",
        "                                            device=device,\n",
        "                                            epoch=epoch)\n",
        "\n",
        "\n",
        "\n",
        "    # validate\n",
        "    val_loss, val_acc = evaluate(model=MNIST_ViT_model,\n",
        "                                 data_loader=Mnist_test_loader,\n",
        "                                 device=device,\n",
        "                                 epoch=epoch)\n",
        "\n",
        "\n",
        "    tags = [\"train_loss\", \"train_acc\", \"val_loss\", \"val_acc\", \"learning_rate\"]\n",
        "    tb_writer.add_scalar(tags[0], train_loss, epoch)\n",
        "    tb_writer.add_scalar(tags[1], train_acc, epoch)\n",
        "    tb_writer.add_scalar(tags[2], val_loss, epoch)\n",
        "    tb_writer.add_scalar(tags[3], val_acc, epoch)\n",
        "    tb_writer.add_scalar(tags[4], optimizer.param_groups[0][\"lr\"], epoch)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmyrgEau3z71"
      },
      "outputs": [],
      "source": [
        "Mnist_ViT_loss={}\n",
        "Mnist_ViT_acc={}\n",
        "\n",
        "\n",
        "for i in range(5):\n",
        "  print(\"train\",i)\n",
        "  torch.manual_seed(i)\n",
        "  epochs=20\n",
        "\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  tb_writer = SummaryWriter()\n",
        "\n",
        "  model = ViT(img_size=28,num_classes=10,patch_size=7,embed_dim=256,depth=3,num_heads=8,in_c=1).to(device)\n",
        "\n",
        "  optimizer = optim.Adam(model.parameters(), lr=0.0003)\n",
        "\n",
        "  Mnist_ViT_loss[\"train_exp_\"+str(i)]=[]\n",
        "  Mnist_ViT_acc[\"train_exp_\"+str(i)]=[]\n",
        "  Mnist_ViT_loss[\"val_exp_\"+str(i)]=[]\n",
        "  Mnist_ViT_acc[\"val_exp_\"+str(i)]=[]\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "      # train\n",
        "      train_loss, train_acc= train_one_epoch(model=model,\n",
        "                                              optimizer=optimizer,\n",
        "                                              data_loader=Mnist_train_loader,\n",
        "                                              device=device,\n",
        "                                              epoch=epoch)\n",
        "\n",
        "      Mnist_ViT_loss[\"train_exp_\"+str(i)].append(train_loss)\n",
        "      Mnist_ViT_acc[\"train_exp_\"+str(i)].append(train_acc)\n",
        "      \n",
        "      # validate\n",
        "      val_loss, val_acc = evaluate(model=model,\n",
        "                                  data_loader=Mnist_test_loader,\n",
        "                                  device=device,\n",
        "                                  epoch=epoch)\n",
        "      end_time=time.time()\n",
        "      Mnist_ViT_loss[\"val_exp_\"+str(i)].append(val_loss)\n",
        "      Mnist_ViT_acc[\"val_exp_\"+str(i)].append(val_acc)\n",
        "      \n",
        "      tags = [\"train_loss\", \"train_acc\", \"val_loss\", \"val_acc\", \"learning_rate\"]\n",
        "      tb_writer.add_scalar(tags[0], train_loss, epoch)\n",
        "      tb_writer.add_scalar(tags[1], train_acc, epoch)\n",
        "      tb_writer.add_scalar(tags[2], val_loss, epoch)\n",
        "      tb_writer.add_scalar(tags[3], val_acc, epoch)\n",
        "      tb_writer.add_scalar(tags[4], optimizer.param_groups[0][\"lr\"], epoch)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHUBdcLzJoRn"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "mnist_vit={\"Mnist_ViT_loss\":Mnist_ViT_loss,\"Mnist_ViT_acc\":Mnist_ViT_acc}\n",
        "mnist_vit_js= json.dumps(mnist_vit) \n",
        " \n",
        "mnist_vit_fileObject = open('/content/drive/MyDrive/mnist_vit.json', 'w')\n",
        "mnist_vit_fileObject.write(mnist_vit_js)\n",
        "mnist_vit_fileObject.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2NLPgffff-d"
      },
      "source": [
        "## Train-ResNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WkiHIjJIuJnR"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(4)\n",
        "\n",
        "epochs=20\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "tb_writer = SummaryWriter()\n",
        "\n",
        "\n",
        "MNIST_res_model = MyResNet().to(device)\n",
        "\n",
        "optimizer = optim.Adam(MNIST_res_model.parameters(), lr=0.0003)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # train\n",
        "    train_loss, train_acc = train_one_epoch(model=MNIST_res_model,\n",
        "                                            optimizer=optimizer,\n",
        "                                            data_loader=Mnist_train_loader,\n",
        "                                            device=device,\n",
        "                                            epoch=epoch)\n",
        "\n",
        "    # validate\n",
        "    val_loss, val_acc = evaluate(model=MNIST_res_model,\n",
        "                                data_loader=Mnist_test_loader,\n",
        "                                device=device,\n",
        "                                epoch=epoch)\n",
        "    tags = [\"train_loss\", \"train_acc\", \"val_loss\", \"val_acc\", \"learning_rate\"]\n",
        "    tb_writer.add_scalar(tags[0], train_loss, epoch)\n",
        "    tb_writer.add_scalar(tags[1], train_acc, epoch)\n",
        "    tb_writer.add_scalar(tags[2], val_loss, epoch)\n",
        "    tb_writer.add_scalar(tags[3], val_acc, epoch)\n",
        "    tb_writer.add_scalar(tags[4], optimizer.param_groups[0][\"lr\"], epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgvD2Gl7Cnfl"
      },
      "outputs": [],
      "source": [
        "Mnist_Res_loss={}\n",
        "Mnist_Res_acc={}\n",
        "\n",
        "\n",
        "for i in range(5):\n",
        "  print(\"train\",i)\n",
        "  torch.manual_seed(i)\n",
        "  epochs=20\n",
        "\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  tb_writer = SummaryWriter()\n",
        "\n",
        "  model = MyResNet().to(device)\n",
        "\n",
        "  optimizer = optim.Adam(model.parameters(), lr=0.00018)\n",
        "\n",
        "  Mnist_Res_loss[\"train_exp_\"+str(i)]=[]\n",
        "  Mnist_Res_acc[\"train_exp_\"+str(i)]=[]\n",
        "  Mnist_Res_loss[\"val_exp_\"+str(i)]=[]\n",
        "  Mnist_Res_acc[\"val_exp_\"+str(i)]=[]\n",
        "  for epoch in range(epochs):\n",
        "      # train\n",
        "      train_loss, train_acc= train_one_epoch(model=model,\n",
        "                                              optimizer=optimizer,\n",
        "                                              data_loader=Mnist_train_loader,\n",
        "                                              device=device,\n",
        "                                              epoch=epoch)\n",
        "\n",
        "      Mnist_Res_loss[\"train_exp_\"+str(i)].append(train_loss)\n",
        "      Mnist_Res_acc[\"train_exp_\"+str(i)].append(train_acc)\n",
        "      \n",
        "      # validate\n",
        "      val_loss, val_acc = evaluate(model=model,\n",
        "                                  data_loader=Mnist_test_loader,\n",
        "                                  device=device,\n",
        "                                  epoch=epoch)\n",
        "     \n",
        "      Mnist_Res_loss[\"val_exp_\"+str(i)].append(val_loss)\n",
        "      Mnist_Res_acc[\"val_exp_\"+str(i)].append(val_acc)\n",
        "      \n",
        "      tags = [\"train_loss\", \"train_acc\", \"val_loss\", \"val_acc\", \"learning_rate\"]\n",
        "      tb_writer.add_scalar(tags[0], train_loss, epoch)\n",
        "      tb_writer.add_scalar(tags[1], train_acc, epoch)\n",
        "      tb_writer.add_scalar(tags[2], val_loss, epoch)\n",
        "      tb_writer.add_scalar(tags[3], val_acc, epoch)\n",
        "      tb_writer.add_scalar(tags[4], optimizer.param_groups[0][\"lr\"], epoch)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5Vz1Wp5Gbn0"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "mnist_res={\"Mnist_Res_loss\":Mnist_Res_loss,\"Mnist_Res_acc\":Mnist_Res_acc}\n",
        "mnist_res_js= json.dumps(mnist_res) \n",
        " \n",
        "mnist_res_fileObject = open('/content/drive/MyDrive/mnist_res.json', 'w')\n",
        "mnist_res_fileObject.write(mnist_res_js)\n",
        "mnist_res_fileObject.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9WbkqCXgs4T"
      },
      "source": [
        "## Experiments with different parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYwEYzi9c9hN"
      },
      "source": [
        "### diff_patch_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fi0jiQIqM5u_"
      },
      "outputs": [],
      "source": [
        "diff_patch_size_train_loss={}\n",
        "diff_patch_size_train_acc={}\n",
        "diff_patch_size_val_loss={}\n",
        "diff_patch_size_val_acc={}\n",
        "diff_patch_size=[2,4,7,14]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eS_Bfj-K8Hg"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(4)\n",
        "for i in diff_patch_size:\n",
        "  epochs=10\n",
        "  lrf=0.01\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  tb_writer = SummaryWriter()\n",
        "\n",
        "  model = ViT(img_size=28,num_classes=10,patch_size=i,embed_dim=32,depth=3,num_heads=4,in_c=1).to(device)\n",
        "\n",
        "  optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
        "\n",
        "  diff_patch_size_train_loss[\"patch_size\"+str(i)]=[]\n",
        "  diff_patch_size_train_acc[\"patch_size\"+str(i)]=[]\n",
        "  diff_patch_size_val_loss[\"patch_size\"+str(i)]=[]\n",
        "  diff_patch_size_val_acc[\"patch_size\"+str(i)]=[]\n",
        "  for epoch in range(epochs):\n",
        "      # train\n",
        "      train_loss, train_acc = train_one_epoch(model=model,\n",
        "                                              optimizer=optimizer,\n",
        "                                              data_loader=Mnist_train_loader,\n",
        "                                              device=device,\n",
        "                                              epoch=epoch)\n",
        "      diff_patch_size_train_loss[\"patch_size\"+str(i)].append(train_loss)\n",
        "      diff_patch_size_train_acc[\"patch_size\"+str(i)].append(train_acc)\n",
        "\n",
        "      # validate\n",
        "      val_loss, val_acc = evaluate(model=model,\n",
        "                                  data_loader=Mnist_test_loader,\n",
        "                                  device=device,\n",
        "                                  epoch=epoch)\n",
        "      \n",
        "      diff_patch_size_val_loss[\"patch_size\"+str(i)].append(val_loss)\n",
        "      diff_patch_size_val_acc[\"patch_size\"+str(i)].append(val_acc)\n",
        "\n",
        "      tags = [\"train_loss\", \"train_acc\", \"val_loss\", \"val_acc\", \"learning_rate\"]\n",
        "      tb_writer.add_scalar(tags[0], train_loss, epoch)\n",
        "      tb_writer.add_scalar(tags[1], train_acc, epoch)\n",
        "      tb_writer.add_scalar(tags[2], val_loss, epoch)\n",
        "      tb_writer.add_scalar(tags[3], val_acc, epoch)\n",
        "      tb_writer.add_scalar(tags[4], optimizer.param_groups[0][\"lr\"], epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-LwQH3DWDYX"
      },
      "outputs": [],
      "source": [
        "#save the results\n",
        "diff_patch_size_res={\"diff_patch_size_train_loss\":diff_patch_size_train_loss,\n",
        "                     \"diff_patch_size_train_acc\":diff_patch_size_train_acc,\n",
        "                     \"diff_patch_size_val_loss\":diff_patch_size_val_loss,\n",
        "                     \"diff_patch_size_val_acc\":diff_patch_size_val_acc}\n",
        "diff_patch_size_res_js= json.dumps(diff_patch_size_res) \n",
        " \n",
        "diff_patch_size_fileObject = open('diff_patch_size.json', 'w')\n",
        "diff_patch_size_fileObject.write(diff_patch_size_res_js)\n",
        "diff_patch_size_fileObject.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzu-SpJp1hko"
      },
      "source": [
        "### diff_dim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otvQn800YSPW"
      },
      "outputs": [],
      "source": [
        "diff_dim=[64,128,256,512,1024]\n",
        "diff_dim_train_loss={}\n",
        "diff_dim_train_acc={}\n",
        "diff_dim_val_loss={}\n",
        "diff_dim_val_acc={}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qw4otDaWU6p6"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(4)\n",
        "for i in diff_dim:\n",
        "  epochs=20\n",
        "  lrf=0.01\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  tb_writer = SummaryWriter()\n",
        "\n",
        "  model = ViT(img_size=28,num_classes=10,patch_size=7,embed_dim=i,depth=6,num_heads=8,in_c=1).to(device)\n",
        "\n",
        "  pg = [p for p in model.parameters() if p.requires_grad]\n",
        "  optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
        "\n",
        "  diff_dim_train_loss[\"embed_dim\"+str(i)]=[]\n",
        "  diff_dim_train_acc[\"embed_dim\"+str(i)]=[]\n",
        "  diff_dim_val_loss[\"embed_dim\"+str(i)]=[]\n",
        "  diff_dim_val_acc[\"embed_dim\"+str(i)]=[]\n",
        "  for epoch in range(epochs):\n",
        "      # train\n",
        "      train_loss, train_acc = train_one_epoch(model=model,\n",
        "                                              optimizer=optimizer,\n",
        "                                              data_loader=Mnist_train_loader,\n",
        "                                              device=device,\n",
        "                                              epoch=epoch)\n",
        "      diff_dim_train_loss[\"embed_dim\"+str(i)].append(train_loss)\n",
        "      diff_dim_train_acc[\"embed_dim\"+str(i)].append(train_acc)\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "      # validate\n",
        "      val_loss, val_acc = evaluate(model=model,\n",
        "                                  data_loader=Mnist_test_loader,\n",
        "                                  device=device,\n",
        "                                  epoch=epoch)\n",
        "      \n",
        "      diff_dim_val_loss[\"embed_dim\"+str(i)].append(val_loss)\n",
        "      diff_dim_val_acc[\"embed_dim\"+str(i)].append(val_acc)\n",
        "\n",
        "      tags = [\"train_loss\", \"train_acc\", \"val_loss\", \"val_acc\", \"learning_rate\"]\n",
        "      tb_writer.add_scalar(tags[0], train_loss, epoch)\n",
        "      tb_writer.add_scalar(tags[1], train_acc, epoch)\n",
        "      tb_writer.add_scalar(tags[2], val_loss, epoch)\n",
        "      tb_writer.add_scalar(tags[3], val_acc, epoch)\n",
        "      tb_writer.add_scalar(tags[4], optimizer.param_groups[0][\"lr\"], epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgRRe6os1th4"
      },
      "outputs": [],
      "source": [
        "diff_dim_res={\"diff_dim_train_loss\":diff_dim_train_loss,\n",
        "                     \"diff_dim_train_acc\":diff_dim_train_acc,\n",
        "                     \"diff_dim_val_loss\":diff_dim_val_loss,\n",
        "                     \"diff_dim_val_acc\":diff_dim_val_acc}\n",
        "diff_dim_res_js= json.dumps(diff_dim_res) \n",
        " \n",
        "diff_dim_fileObject = open('/content/drive/MyDrive/diff_dim.json', 'w')\n",
        "diff_dim_fileObject.write(diff_dim_res_js)\n",
        "diff_dim_fileObject.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MiCRuwu1uh3"
      },
      "source": [
        "### diff_depth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2DrIVxyzc627"
      },
      "outputs": [],
      "source": [
        "diff_depth=[3,6,9,12]\n",
        "diff_depth_train_loss={}\n",
        "diff_depth_train_acc={}\n",
        "diff_depth_val_loss={}\n",
        "diff_depth_val_acc={}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3sHiJBQ5eGw6"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(4)\n",
        "for i in diff_depth:\n",
        "  epochs=20\n",
        "  lrf=0.01\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  tb_writer = SummaryWriter()\n",
        "\n",
        "  model = ViT(img_size=28,num_classes=10,patch_size=7,embed_dim=64,depth=i,num_heads=8,in_c=1).to(device)\n",
        "\n",
        "  pg = [p for p in model.parameters() if p.requires_grad]\n",
        "  optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
        "\n",
        "  diff_depth_train_loss[\"diff_depth\"+str(i)]=[]\n",
        "  diff_depth_train_acc[\"diff_depth\"+str(i)]=[]\n",
        "  diff_depth_val_loss[\"diff_depth\"+str(i)]=[]\n",
        "  diff_depth_val_acc[\"diff_depth\"+str(i)]=[]\n",
        "  for epoch in range(epochs):\n",
        "      # train\n",
        "      train_loss, train_acc = train_one_epoch(model=model,\n",
        "                                              optimizer=optimizer,\n",
        "                                              data_loader=Mnist_train_loader,\n",
        "                                              device=device,\n",
        "                                              epoch=epoch)\n",
        "      diff_depth_train_loss[\"diff_depth\"+str(i)].append(train_loss)\n",
        "      diff_depth_train_acc[\"diff_depth\"+str(i)].append(train_acc)\n",
        "\n",
        "      # validate\n",
        "      val_loss, val_acc = evaluate(model=model,\n",
        "                                  data_loader=Mnist_test_loader,\n",
        "                                  device=device,\n",
        "                                  epoch=epoch)\n",
        "      \n",
        "      diff_depth_val_loss[\"diff_depth\"+str(i)].append(val_loss)\n",
        "      diff_depth_val_acc[\"diff_depth\"+str(i)].append(val_acc)\n",
        "\n",
        "      tags = [\"train_loss\", \"train_acc\", \"val_loss\", \"val_acc\", \"learning_rate\"]\n",
        "      tb_writer.add_scalar(tags[0], train_loss, epoch)\n",
        "      tb_writer.add_scalar(tags[1], train_acc, epoch)\n",
        "      tb_writer.add_scalar(tags[2], val_loss, epoch)\n",
        "      tb_writer.add_scalar(tags[3], val_acc, epoch)\n",
        "      tb_writer.add_scalar(tags[4], optimizer.param_groups[0][\"lr\"], epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "r7yv5xMExFu-"
      },
      "outputs": [],
      "source": [
        "diff_depth_res={\"diff_depth_train_loss\":diff_depth_train_loss,\n",
        "                     \"diff_depth_train_acc\":diff_depth_train_acc,\n",
        "                     \"diff_depth_val_loss\":diff_depth_val_loss,\n",
        "                     \"diff_depth_val_acc\":diff_depth_val_acc}\n",
        "diff_depth_res_js= json.dumps(diff_depth_res) \n",
        " \n",
        "diff_depth_fileObject = open('/content/drive/MyDrive/diff_depth.json', 'w')\n",
        "diff_depth_fileObject.write(diff_depth_res_js)\n",
        "diff_depth_fileObject.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7FJj7u-cz7q"
      },
      "source": [
        "### diff_num_heads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "z5aFE5OIesmA"
      },
      "outputs": [],
      "source": [
        "diff_num_heads=[8,16,32]\n",
        "diff_num_heads_train_loss={}\n",
        "diff_num_heads_train_acc={}\n",
        "diff_num_heads_val_loss={}\n",
        "diff_num_heads_val_acc={}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7uYjwL74etD_"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(4)\n",
        "for i in diff_num_heads:\n",
        "  epochs=20\n",
        "  lrf=0.01\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  tb_writer = SummaryWriter()\n",
        "\n",
        "  model = ViT(img_size=28,num_classes=10,patch_size=7,embed_dim=64,depth=6,num_heads=i,in_c=1).to(device)\n",
        "\n",
        "  optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
        "\n",
        "  diff_num_heads_train_loss[\"num_heads\"+str(i)]=[]\n",
        "  diff_num_heads_train_acc[\"num_heads\"+str(i)]=[]\n",
        "  diff_num_heads_val_loss[\"num_heads\"+str(i)]=[]\n",
        "  diff_num_heads_val_acc[\"num_heads\"+str(i)]=[]\n",
        "  for epoch in range(epochs):\n",
        "      # train\n",
        "      train_loss, train_acc = train_one_epoch(model=model,\n",
        "                                              optimizer=optimizer,\n",
        "                                              data_loader=Mnist_train_loader,\n",
        "                                              device=device,\n",
        "                                              epoch=epoch)\n",
        "      diff_num_heads_train_loss[\"num_heads\"+str(i)].append(train_loss)\n",
        "      diff_num_heads_train_acc[\"num_heads\"+str(i)].append(train_acc)\n",
        "\n",
        "\n",
        "      # scheduler.step()\n",
        "\n",
        "      # validate\n",
        "      val_loss, val_acc = evaluate(model=model,\n",
        "                                  data_loader=Mnist_test_loader,\n",
        "                                  device=device,\n",
        "                                  epoch=epoch)\n",
        "      \n",
        "      diff_num_heads_val_loss[\"num_heads\"+str(i)].append(val_loss)\n",
        "      diff_num_heads_val_acc[\"num_heads\"+str(i)].append(val_acc)\n",
        "\n",
        "      tags = [\"train_loss\", \"train_acc\", \"val_loss\", \"val_acc\", \"learning_rate\"]\n",
        "      tb_writer.add_scalar(tags[0], train_loss, epoch)\n",
        "      tb_writer.add_scalar(tags[1], train_acc, epoch)\n",
        "      tb_writer.add_scalar(tags[2], val_loss, epoch)\n",
        "      tb_writer.add_scalar(tags[3], val_acc, epoch)\n",
        "      tb_writer.add_scalar(tags[4], optimizer.param_groups[0][\"lr\"], epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27hrByHghbCP"
      },
      "outputs": [],
      "source": [
        "diff_num_heads_res={\"diff_num_heads_train_loss\":diff_num_heads_train_loss,\n",
        "                     \"diff_num_heads_train_acc\":diff_num_heads_train_acc,\n",
        "                     \"diff_num_heads_val_loss\":diff_num_heads_val_loss,\n",
        "                     \"diff_num_heads_val_acc\":diff_num_heads_val_acc}\n",
        "diff_num_heads_res_js= json.dumps(diff_num_heads_res) \n",
        " \n",
        "diff_num_heads_fileObject = open('/content/drive/MyDrive/diff_num_heads.json', 'w')\n",
        "diff_num_heads_fileObject.write(diff_num_heads_res_js)\n",
        "diff_num_heads_fileObject.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5DREXxbESJL"
      },
      "source": [
        "### diff_lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gC1hDVRPgoA_"
      },
      "outputs": [],
      "source": [
        "diff_lr=[0.0001,0.0005,0.001,0.003,0.005,0.01]\n",
        "diff_lr_train_loss={}\n",
        "diff_lr_train_acc={}\n",
        "diff_lr_val_loss={}\n",
        "diff_lr_val_acc={}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLMqleX_goaK"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(4)\n",
        "for i in diff_lr:\n",
        "  epochs=20\n",
        "  lrf=0.01\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  tb_writer = SummaryWriter()\n",
        "\n",
        "  model = ViT(img_size=28,num_classes=10,patch_size=7,embed_dim=64,depth=6,num_heads=8,in_c=1).to(device)\n",
        "\n",
        "  pg = [p for p in model.parameters() if p.requires_grad]\n",
        "  optimizer = optim.Adam(model.parameters(), lr=i)\n",
        " \n",
        "  diff_lr_train_loss[\"lr\"+str(i)]=[]\n",
        "  diff_lr_train_acc[\"lr\"+str(i)]=[]\n",
        "  diff_lr_val_loss[\"lr\"+str(i)]=[]\n",
        "  diff_lr_val_acc[\"lr\"+str(i)]=[]\n",
        "  for epoch in range(epochs):\n",
        "      # train\n",
        "      train_loss, train_acc = train_one_epoch(model=model,\n",
        "                                              optimizer=optimizer,\n",
        "                                              data_loader=Mnist_train_loader,\n",
        "                                              device=device,\n",
        "                                              epoch=epoch)\n",
        "      diff_lr_train_loss[\"lr\"+str(i)].append(train_loss)\n",
        "      diff_lr_train_acc[\"lr\"+str(i)].append(train_acc)\n",
        "\n",
        "\n",
        "      # validate\n",
        "      val_loss, val_acc = evaluate(model=model,\n",
        "                                  data_loader=Mnist_test_loader,\n",
        "                                  device=device,\n",
        "                                  epoch=epoch)\n",
        "      \n",
        "      diff_lr_val_loss[\"lr\"+str(i)].append(val_loss)\n",
        "      diff_lr_val_acc[\"lr\"+str(i)].append(val_acc)\n",
        "\n",
        "      tags = [\"train_loss\", \"train_acc\", \"val_loss\", \"val_acc\", \"learning_rate\"]\n",
        "      tb_writer.add_scalar(tags[0], train_loss, epoch)\n",
        "      tb_writer.add_scalar(tags[1], train_acc, epoch)\n",
        "      tb_writer.add_scalar(tags[2], val_loss, epoch)\n",
        "      tb_writer.add_scalar(tags[3], val_acc, epoch)\n",
        "      tb_writer.add_scalar(tags[4], optimizer.param_groups[0][\"lr\"], epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4KJ_jnoOgoqW"
      },
      "outputs": [],
      "source": [
        "diff_lr_res={\"diff_lr_train_loss\":diff_lr_train_loss,\n",
        "                     \"diff_lr_train_acc\":diff_lr_train_acc,\n",
        "                     \"diff_lr_val_loss\":diff_lr_val_loss,\n",
        "                     \"diff_lr_val_acc\":diff_lr_val_acc}\n",
        "diff_lr_res_js= json.dumps(diff_lr_res) \n",
        " \n",
        "diff_lr_fileObject = open('/content/drive/MyDrive/diff_lr.json', 'w')\n",
        "diff_lr_fileObject.write(diff_lr_res_js)\n",
        "diff_lr_fileObject.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GC9grAQ-pVRi"
      },
      "source": [
        "# CIFAR-10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cr-jfHXHpjrM"
      },
      "source": [
        "## Get Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zH8NrWfRpUG9"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "CIF_trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "CIF_trainloader = torch.utils.data.DataLoader(CIF_trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=4)\n",
        "\n",
        "CIF_testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "CIF_testloader = torch.utils.data.DataLoader(CIF_testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IpcSRZY4qBMh"
      },
      "outputs": [],
      "source": [
        "images, labels = next(iter(CIF_trainloader))\n",
        "print(images.size())\n",
        "plt.figure(figsize=(9, 9))\n",
        "for i in range(9):\n",
        "    plt.subplot(3, 3, i+1)\n",
        "    plt.title(labels[i].item())\n",
        "    img=images[i].permute(1, 2, 0)\n",
        "    plt.imshow(torch.squeeze(img, dim=2), cmap='gray')\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lShG7AZ_4eWD"
      },
      "source": [
        "## Train-ViT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32yeuz3rjEI7"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(4)\n",
        "epochs=20\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "tb_writer = SummaryWriter()\n",
        "\n",
        "CIF_vit_model = ViT(img_size=32,num_classes=10,patch_size=4,embed_dim=96,depth=6,num_heads=8,in_c=3).to(device)\n",
        "\n",
        "optimizer = optim.Adam(CIF_vit_model.parameters(), lr=0.0003)\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # train\n",
        "    train_loss, train_acc= train_one_epoch(model=CIF_vit_model,\n",
        "                                            optimizer=optimizer,\n",
        "                                            data_loader=CIF_trainloader,\n",
        "                                            device=device,\n",
        "                                            epoch=epoch)\n",
        "\n",
        "\n",
        "    # validate\n",
        "    val_loss, val_acc = evaluate(model=CIF_vit_model,\n",
        "                                data_loader=CIF_testloader,\n",
        "                                device=device,\n",
        "                                epoch=epoch)\n",
        "\n",
        "      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wg8BkyQ_pnz2"
      },
      "outputs": [],
      "source": [
        "CIF_ViT_loss={}\n",
        "CIF_ViT_acc={}\n",
        "\n",
        "\n",
        "for i in range(5):\n",
        "  print(\"train\",i)\n",
        "  torch.manual_seed(i)\n",
        "  epochs=20\n",
        "\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  tb_writer = SummaryWriter()\n",
        "\n",
        "  model = ViT(img_size=32,num_classes=10,patch_size=4,embed_dim=96,depth=6,num_heads=8,in_c=3).to(device)\n",
        "\n",
        "  optimizer = optim.Adam(model.parameters(), lr=0.0003)\n",
        "\n",
        "  CIF_ViT_loss[\"train_exp_\"+str(i)]=[]\n",
        "  CIF_ViT_acc[\"train_exp_\"+str(i)]=[]\n",
        "  CIF_ViT_loss[\"val_exp_\"+str(i)]=[]\n",
        "  CIF_ViT_acc[\"val_exp_\"+str(i)]=[]\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "      # train\n",
        "      train_loss, train_acc= train_one_epoch(model=model,\n",
        "                                              optimizer=optimizer,\n",
        "                                              data_loader=CIF_trainloader,\n",
        "                                              device=device,\n",
        "                                              epoch=epoch)\n",
        "\n",
        "      CIF_ViT_loss[\"train_exp_\"+str(i)].append(train_loss)\n",
        "      CIF_ViT_acc[\"train_exp_\"+str(i)].append(train_acc)\n",
        "      \n",
        "      # validate\n",
        "      val_loss, val_acc = evaluate(model=model,\n",
        "                                  data_loader=CIF_testloader,\n",
        "                                  device=device,\n",
        "                                  epoch=epoch)\n",
        "      end_time=time.time()\n",
        "      CIF_ViT_loss[\"val_exp_\"+str(i)].append(val_loss)\n",
        "      CIF_ViT_acc[\"val_exp_\"+str(i)].append(val_acc)\n",
        "      \n",
        "      tags = [\"train_loss\", \"train_acc\", \"val_loss\", \"val_acc\", \"learning_rate\"]\n",
        "      tb_writer.add_scalar(tags[0], train_loss, epoch)\n",
        "      tb_writer.add_scalar(tags[1], train_acc, epoch)\n",
        "      tb_writer.add_scalar(tags[2], val_loss, epoch)\n",
        "      tb_writer.add_scalar(tags[3], val_acc, epoch)\n",
        "      tb_writer.add_scalar(tags[4], optimizer.param_groups[0][\"lr\"], epoch)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDmGsxjpRexJ"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "CIF_vit={\"CIF_ViT_loss\":CIF_ViT_loss,\"CIF_ViT_acc\":CIF_ViT_acc}\n",
        "CIF_vit_js= json.dumps(CIF_vit) \n",
        " \n",
        "CIF_vit_fileObject = open('/content/drive/MyDrive/CIF_vit.json', 'w')\n",
        "CIF_vit_fileObject.write(CIF_vit_js)\n",
        "CIF_vit_fileObject.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQ3CHlAESa0O"
      },
      "source": [
        "## Train-Resnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1j1FoSrHSnzK"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(4)\n",
        "\n",
        "epochs=20\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "tb_writer = SummaryWriter()\n",
        "\n",
        "\n",
        "CIF_res_model = MyResNet().to(device)\n",
        "\n",
        "optimizer = optim.Adam(CIF_res_model.parameters(), lr=0.0003)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # train\n",
        "    train_loss, train_acc = train_one_epoch(model=CIF_res_model,\n",
        "                                            optimizer=optimizer,\n",
        "                                            data_loader=CIF_trainloader,\n",
        "                                            device=device,\n",
        "                                            epoch=epoch)\n",
        "\n",
        "    # validate\n",
        "    val_loss, val_acc = evaluate(model=CIF_res_model,\n",
        "                                data_loader=CIF_testloader,\n",
        "                                device=device,\n",
        "                                epoch=epoch)\n",
        "    tags = [\"train_loss\", \"train_acc\", \"val_loss\", \"val_acc\", \"learning_rate\"]\n",
        "    tb_writer.add_scalar(tags[0], train_loss, epoch)\n",
        "    tb_writer.add_scalar(tags[1], train_acc, epoch)\n",
        "    tb_writer.add_scalar(tags[2], val_loss, epoch)\n",
        "    tb_writer.add_scalar(tags[3], val_acc, epoch)\n",
        "    tb_writer.add_scalar(tags[4], optimizer.param_groups[0][\"lr\"], epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-2qq9z29q7W"
      },
      "outputs": [],
      "source": [
        "CIF_Res_loss={}\n",
        "CIF_Res_acc={}\n",
        "\n",
        "\n",
        "for i in range(5):\n",
        "  print(\"train\",i)\n",
        "  torch.manual_seed(i)\n",
        "  epochs=20\n",
        "\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "  model = MyResNet().to(device)\n",
        "\n",
        "  optimizer = optim.Adam(model.parameters(), lr=0.0003)\n",
        "\n",
        "  CIF_Res_loss[\"train_exp_\"+str(i)]=[]\n",
        "  CIF_Res_acc[\"train_exp_\"+str(i)]=[]\n",
        "  CIF_Res_loss[\"val_exp_\"+str(i)]=[]\n",
        "  CIF_Res_acc[\"val_exp_\"+str(i)]=[]\n",
        "  for epoch in range(epochs):\n",
        "      # train\n",
        "      train_loss, train_acc= train_one_epoch(model=model,\n",
        "                                              optimizer=optimizer,\n",
        "                                              data_loader=CIF_trainloader,\n",
        "                                              device=device,\n",
        "                                              epoch=epoch)\n",
        "\n",
        "      CIF_Res_loss[\"train_exp_\"+str(i)].append(train_loss)\n",
        "      CIF_Res_acc[\"train_exp_\"+str(i)].append(train_acc)\n",
        "      \n",
        "      # validate\n",
        "      val_loss, val_acc = evaluate(model=model,\n",
        "                                  data_loader=CIF_testloader,\n",
        "                                  device=device,\n",
        "                                  epoch=epoch)\n",
        "     \n",
        "      CIF_Res_loss[\"val_exp_\"+str(i)].append(val_loss)\n",
        "      CIF_Res_acc[\"val_exp_\"+str(i)].append(val_acc)\n",
        "      \n",
        "      tags = [\"train_loss\", \"train_acc\", \"val_loss\", \"val_acc\", \"learning_rate\"]\n",
        "      tb_writer.add_scalar(tags[0], train_loss, epoch)\n",
        "      tb_writer.add_scalar(tags[1], train_acc, epoch)\n",
        "      tb_writer.add_scalar(tags[2], val_loss, epoch)\n",
        "      tb_writer.add_scalar(tags[3], val_acc, epoch)\n",
        "      tb_writer.add_scalar(tags[4], optimizer.param_groups[0][\"lr\"], epoch)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVxA-oBmS6L_"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "CIF_res={\"CIF_Res_loss\":CIF_Res_loss,\"CIF_Res_acc\":CIF_Res_acc}\n",
        "CIF_res_js= json.dumps(CIF_res) \n",
        " \n",
        "CIF_res_fileObject = open('/content/drive/MyDrive/CIF_res.json', 'w')\n",
        "CIF_res_fileObject.write(CIF_res_js)\n",
        "CIF_res_fileObject.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjn6lQey_EVv"
      },
      "source": [
        "## Experiments with different parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aw-nfaXD_EVv"
      },
      "source": [
        "### diff_patch_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VmN_XUjK_EVw"
      },
      "outputs": [],
      "source": [
        "diff_patch_size_train_loss={}\n",
        "diff_patch_size_train_acc={}\n",
        "diff_patch_size_val_loss={}\n",
        "diff_patch_size_val_acc={}\n",
        "diff_patch_size=[2,4,8]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMc4zKVy_EVw"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(4)\n",
        "for i in diff_patch_size:\n",
        "  epochs=20\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "  model = ViT(img_size=32,num_classes=10,patch_size=i,embed_dim=96,depth=6,num_heads=6,in_c=3).to(device)\n",
        "\n",
        "  optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
        "\n",
        "  diff_patch_size_train_loss[\"patch_size\"+str(i)]=[]\n",
        "  diff_patch_size_train_acc[\"patch_size\"+str(i)]=[]\n",
        "  diff_patch_size_val_loss[\"patch_size\"+str(i)]=[]\n",
        "  diff_patch_size_val_acc[\"patch_size\"+str(i)]=[]\n",
        "  for epoch in range(epochs):\n",
        "      # train\n",
        "      train_loss, train_acc = train_one_epoch(model=model,\n",
        "                                              optimizer=optimizer,\n",
        "                                              data_loader=CIF_trainloader,\n",
        "                                              device=device,\n",
        "                                              epoch=epoch)\n",
        "      diff_patch_size_train_loss[\"patch_size\"+str(i)].append(train_loss)\n",
        "      diff_patch_size_train_acc[\"patch_size\"+str(i)].append(train_acc)\n",
        "\n",
        "      # validate\n",
        "      val_loss, val_acc = evaluate(model=model,\n",
        "                                  data_loader=CIF_testloader,\n",
        "                                  device=device,\n",
        "                                  epoch=epoch)\n",
        "      \n",
        "      diff_patch_size_val_loss[\"patch_size\"+str(i)].append(val_loss)\n",
        "      diff_patch_size_val_acc[\"patch_size\"+str(i)].append(val_acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09DprZfJ_EVw"
      },
      "outputs": [],
      "source": [
        "#save the results\n",
        "diff_patch_size_res={\"diff_patch_size_train_loss\":diff_patch_size_train_loss,\n",
        "                     \"diff_patch_size_train_acc\":diff_patch_size_train_acc,\n",
        "                     \"diff_patch_size_val_loss\":diff_patch_size_val_loss,\n",
        "                     \"diff_patch_size_val_acc\":diff_patch_size_val_acc}\n",
        "diff_patch_size_res_js= json.dumps(diff_patch_size_res) \n",
        " \n",
        "diff_patch_size_fileObject = open('/content/drive/MyDrive/CIF_diff_patch_size.json', 'w')\n",
        "diff_patch_size_fileObject.write(diff_patch_size_res_js)\n",
        "diff_patch_size_fileObject.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUNeHD_4_EVx"
      },
      "source": [
        "### diff_dim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2wge_Y8R_EVx"
      },
      "outputs": [],
      "source": [
        "diff_dim=[48,96,192,384,768]\n",
        "diff_dim_train_loss={}\n",
        "diff_dim_train_acc={}\n",
        "diff_dim_val_loss={}\n",
        "diff_dim_val_acc={}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PR3cmFkA_EVx"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(4)\n",
        "for i in diff_dim:\n",
        "  epochs=20\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "  \n",
        "  model = ViT(img_size=32,num_classes=10,patch_size=8,embed_dim=i,depth=6,num_heads=8,in_c=3).to(device)\n",
        "\n",
        "  optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
        "\n",
        "  diff_dim_train_loss[\"embed_dim\"+str(i)]=[]\n",
        "  diff_dim_train_acc[\"embed_dim\"+str(i)]=[]\n",
        "  diff_dim_val_loss[\"embed_dim\"+str(i)]=[]\n",
        "  diff_dim_val_acc[\"embed_dim\"+str(i)]=[]\n",
        "  for epoch in range(epochs):\n",
        "      # train\n",
        "      train_loss, train_acc = train_one_epoch(model=model,\n",
        "                                              optimizer=optimizer,\n",
        "                                              data_loader=CIF_trainloader,\n",
        "                                              device=device,\n",
        "                                              epoch=epoch)\n",
        "      diff_dim_train_loss[\"embed_dim\"+str(i)].append(train_loss)\n",
        "      diff_dim_train_acc[\"embed_dim\"+str(i)].append(train_acc)\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "      # validate\n",
        "      val_loss, val_acc = evaluate(model=model,\n",
        "                                  data_loader=CIF_testloader,\n",
        "                                  device=device,\n",
        "                                  epoch=epoch)\n",
        "      \n",
        "      diff_dim_val_loss[\"embed_dim\"+str(i)].append(val_loss)\n",
        "      diff_dim_val_acc[\"embed_dim\"+str(i)].append(val_acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7DBwHP9_EVy"
      },
      "outputs": [],
      "source": [
        "diff_dim_res={\"diff_dim_train_loss\":diff_dim_train_loss,\n",
        "                     \"diff_dim_train_acc\":diff_dim_train_acc,\n",
        "                     \"diff_dim_val_loss\":diff_dim_val_loss,\n",
        "                     \"diff_dim_val_acc\":diff_dim_val_acc}\n",
        "diff_dim_res_js= json.dumps(diff_dim_res) \n",
        " \n",
        "diff_dim_fileObject = open('/content/drive/MyDrive/CIR_diff_dim.json', 'w')\n",
        "diff_dim_fileObject.write(diff_dim_res_js)\n",
        "diff_dim_fileObject.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEGD6tPg_EVy"
      },
      "source": [
        "### diff_depth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdwGpHUr_EVy"
      },
      "outputs": [],
      "source": [
        "diff_depth=[3,6,9,12]\n",
        "diff_depth_train_loss={}\n",
        "diff_depth_train_acc={}\n",
        "diff_depth_val_loss={}\n",
        "diff_depth_val_acc={}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqr3ZOsy_EVy"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(4)\n",
        "for i in diff_depth:\n",
        "  epochs=20\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  model = ViT(img_size=32,num_classes=10,patch_size=8,embed_dim=96,depth=i,num_heads=6,in_c=3).to(device)\n",
        "  optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
        "\n",
        "  diff_depth_train_loss[\"diff_depth\"+str(i)]=[]\n",
        "  diff_depth_train_acc[\"diff_depth\"+str(i)]=[]\n",
        "  diff_depth_val_loss[\"diff_depth\"+str(i)]=[]\n",
        "  diff_depth_val_acc[\"diff_depth\"+str(i)]=[]\n",
        "  for epoch in range(epochs):\n",
        "      # train\n",
        "      train_loss, train_acc = train_one_epoch(model=model,\n",
        "                                              optimizer=optimizer,\n",
        "                                              data_loader=CIF_trainloader,\n",
        "                                              device=device,\n",
        "                                              epoch=epoch)\n",
        "      diff_depth_train_loss[\"diff_depth\"+str(i)].append(train_loss)\n",
        "      diff_depth_train_acc[\"diff_depth\"+str(i)].append(train_acc)\n",
        "\n",
        "      # validate\n",
        "      val_loss, val_acc = evaluate(model=model,\n",
        "                                  data_loader=CIF_testloader,\n",
        "                                  device=device,\n",
        "                                  epoch=epoch)\n",
        "      \n",
        "      diff_depth_val_loss[\"diff_depth\"+str(i)].append(val_loss)\n",
        "      diff_depth_val_acc[\"diff_depth\"+str(i)].append(val_acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mycyMeb0_EVy"
      },
      "outputs": [],
      "source": [
        "diff_depth_res={\"diff_depth_train_loss\":diff_depth_train_loss,\n",
        "                     \"diff_depth_train_acc\":diff_depth_train_acc,\n",
        "                     \"diff_depth_val_loss\":diff_depth_val_loss,\n",
        "                     \"diff_depth_val_acc\":diff_depth_val_acc}\n",
        "diff_depth_res_js= json.dumps(diff_depth_res) \n",
        " \n",
        "diff_depth_fileObject = open('/content/drive/MyDrive/CIF_diff_depth.json', 'w')\n",
        "diff_depth_fileObject.write(diff_depth_res_js)\n",
        "diff_depth_fileObject.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qZn4izG_EVz"
      },
      "source": [
        "### diff_num_heads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuxPbx-G_EVz"
      },
      "outputs": [],
      "source": [
        "diff_num_heads=[6,8,12]\n",
        "diff_num_heads_train_loss={}\n",
        "diff_num_heads_train_acc={}\n",
        "diff_num_heads_val_loss={}\n",
        "diff_num_heads_val_acc={}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwfyDVrP_EVz"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(4)\n",
        "for i in diff_num_heads:\n",
        "  epochs=20\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  model = ViT(img_size=32,num_classes=10,patch_size=8,embed_dim=96,depth=6,num_heads=i,in_c=3).to(device)\n",
        " \n",
        "  optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "  diff_num_heads_train_loss[\"num_heads\"+str(i)]=[]\n",
        "  diff_num_heads_train_acc[\"num_heads\"+str(i)]=[]\n",
        "  diff_num_heads_val_loss[\"num_heads\"+str(i)]=[]\n",
        "  diff_num_heads_val_acc[\"num_heads\"+str(i)]=[]\n",
        "  for epoch in range(epochs):\n",
        "      # train\n",
        "      train_loss, train_acc = train_one_epoch(model=model,\n",
        "                                              optimizer=optimizer,\n",
        "                                              data_loader=CIF_trainloader,\n",
        "                                              device=device,\n",
        "                                              epoch=epoch)\n",
        "      diff_num_heads_train_loss[\"num_heads\"+str(i)].append(train_loss)\n",
        "      diff_num_heads_train_acc[\"num_heads\"+str(i)].append(train_acc)\n",
        "\n",
        "      # validate\n",
        "      val_loss, val_acc = evaluate(model=model,\n",
        "                                  data_loader=CIF_testloader,\n",
        "                                  device=device,\n",
        "                                  epoch=epoch)\n",
        "      \n",
        "      diff_num_heads_val_loss[\"num_heads\"+str(i)].append(val_loss)\n",
        "      diff_num_heads_val_acc[\"num_heads\"+str(i)].append(val_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhJNueixoOha"
      },
      "outputs": [],
      "source": [
        "diff_num_heads=[6,8,12]\n",
        "diff_num_heads_train_loss={}\n",
        "diff_num_heads_train_acc={}\n",
        "diff_num_heads_val_loss={}\n",
        "diff_num_heads_val_acc={}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3OFUM4HjoIEK"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(4)\n",
        "for i in diff_num_heads:\n",
        "  epochs=20\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  model = ViT(img_size=32,num_classes=10,patch_size=8,embed_dim=96,depth=6,num_heads=i,in_c=3).to(device)\n",
        " \n",
        "  optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
        "\n",
        "  diff_num_heads_train_loss[\"num_heads\"+str(i)]=[]\n",
        "  diff_num_heads_train_acc[\"num_heads\"+str(i)]=[]\n",
        "  diff_num_heads_val_loss[\"num_heads\"+str(i)]=[]\n",
        "  diff_num_heads_val_acc[\"num_heads\"+str(i)]=[]\n",
        "  for epoch in range(epochs):\n",
        "      # train\n",
        "      train_loss, train_acc = train_one_epoch(model=model,\n",
        "                                              optimizer=optimizer,\n",
        "                                              data_loader=CIF_trainloader,\n",
        "                                              device=device,\n",
        "                                              epoch=epoch)\n",
        "      diff_num_heads_train_loss[\"num_heads\"+str(i)].append(train_loss)\n",
        "      diff_num_heads_train_acc[\"num_heads\"+str(i)].append(train_acc)\n",
        "\n",
        "      # validate\n",
        "      val_loss, val_acc = evaluate(model=model,\n",
        "                                  data_loader=CIF_testloader,\n",
        "                                  device=device,\n",
        "                                  epoch=epoch)\n",
        "      \n",
        "      diff_num_heads_val_loss[\"num_heads\"+str(i)].append(val_loss)\n",
        "      diff_num_heads_val_acc[\"num_heads\"+str(i)].append(val_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RIagNwzc_EVz"
      },
      "outputs": [],
      "source": [
        "diff_num_heads_res={\"diff_num_heads_train_loss\":diff_num_heads_train_loss,\n",
        "                     \"diff_num_heads_train_acc\":diff_num_heads_train_acc,\n",
        "                     \"diff_num_heads_val_loss\":diff_num_heads_val_loss,\n",
        "                     \"diff_num_heads_val_acc\":diff_num_heads_val_acc}\n",
        "diff_num_heads_res_js= json.dumps(diff_num_heads_res) \n",
        " \n",
        "diff_num_heads_fileObject = open('/content/drive/MyDrive/CIF_diff_num_heads.json', 'w')\n",
        "diff_num_heads_fileObject.write(diff_num_heads_res_js)\n",
        "diff_num_heads_fileObject.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HC6iZ2oW_EV0"
      },
      "source": [
        "### diff_lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVtOGETZ_EV0"
      },
      "outputs": [],
      "source": [
        "diff_lr=[0.0001,0.0005,0.001,0.003,0.005,0.01]\n",
        "diff_lr_train_loss={}\n",
        "diff_lr_train_acc={}\n",
        "diff_lr_val_loss={}\n",
        "diff_lr_val_acc={}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knrGARy5_EV0"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(4)\n",
        "for i in diff_lr:\n",
        "  epochs=20\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  model = ViT(img_size=32,num_classes=10,patch_size=8,embed_dim=96,depth=6,num_heads=6,in_c=3).to(device)\n",
        "\n",
        "  optimizer = optim.Adam(model.parameters(), lr=i)\n",
        "  \n",
        "  diff_lr_train_loss[\"lr\"+str(i)]=[]\n",
        "  diff_lr_train_acc[\"lr\"+str(i)]=[]\n",
        "  diff_lr_val_loss[\"lr\"+str(i)]=[]\n",
        "  diff_lr_val_acc[\"lr\"+str(i)]=[]\n",
        "  for epoch in range(epochs):\n",
        "      # train\n",
        "      train_loss, train_acc = train_one_epoch(model=model,\n",
        "                                              optimizer=optimizer,\n",
        "                                              data_loader=CIF_trainloader,\n",
        "                                              device=device,\n",
        "                                              epoch=epoch)\n",
        "      diff_lr_train_loss[\"lr\"+str(i)].append(train_loss)\n",
        "      diff_lr_train_acc[\"lr\"+str(i)].append(train_acc)\n",
        "\n",
        "\n",
        "      # validate\n",
        "      val_loss, val_acc = evaluate(model=model,\n",
        "                                  data_loader=CIF_testloader,\n",
        "                                  device=device,\n",
        "                                  epoch=epoch)\n",
        "      \n",
        "      diff_lr_val_loss[\"lr\"+str(i)].append(val_loss)\n",
        "      diff_lr_val_acc[\"lr\"+str(i)].append(val_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDhBtLr9_EV0"
      },
      "outputs": [],
      "source": [
        "diff_lr_res={\"diff_lr_train_loss\":diff_lr_train_loss,\n",
        "                     \"diff_lr_train_acc\":diff_lr_train_acc,\n",
        "                     \"diff_lr_val_loss\":diff_lr_val_loss,\n",
        "                     \"diff_lr_val_acc\":diff_lr_val_acc}\n",
        "diff_lr_res_js= json.dumps(diff_lr_res) \n",
        " \n",
        "diff_lr_fileObject = open('/content/drive/MyDrive/CIF_diff_lr2.json', 'w')\n",
        "diff_lr_fileObject.write(diff_lr_res_js)\n",
        "diff_lr_fileObject.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYxStlX5bXHP"
      },
      "source": [
        "# PCAM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACkFkZgZLsDV"
      },
      "source": [
        "## Get Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vGykzHF73UT"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/drive/MyDrive/data/PCAM/pcam ./pcam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SzUazXDLHTgB"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "data_transform = {\n",
        "    \"train\": transforms.Compose([ \n",
        "                                \n",
        "                                 transforms.ToTensor(),\n",
        "                                 transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "                                 ]),\n",
        "    \"val\": transforms.Compose([transforms.ToTensor(),\n",
        "                               transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
        "                               ])}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFpVe_T5KSIt"
      },
      "outputs": [],
      "source": [
        "PCAM_DOWNLOAD_PATH = './'\n",
        "PCAM_train_set = torchvision.datasets.PCAM(PCAM_DOWNLOAD_PATH, split=\"train\", transform=data_transform['train'],download=True)\n",
        "PCAM_val_dataset = torchvision.datasets.PCAM(PCAM_DOWNLOAD_PATH, split=\"val\", transform=data_transform['val'],download=True)\n",
        "\n",
        "PCAM_train_loader = torch.utils.data.DataLoader(PCAM_train_set,batch_size=batch_size,shuffle=True,num_workers=4)\n",
        "PCAM_val_loader =torch.utils.data.DataLoader(PCAM_val_dataset,batch_size=batch_size,shuffle=False,num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lSyIPSfLPd1"
      },
      "outputs": [],
      "source": [
        "from torchvision.utils import save_image\n",
        "images, labels = next(iter(PCAM_train_loader))\n",
        "print(images.size())\n",
        "plt.figure(figsize=(9, 9))\n",
        "for i in range(9):\n",
        "    ax=plt.subplot(3, 3, i+1)\n",
        "    if labels[i].item()==1:\n",
        "      tit=\"Tumor\"\n",
        "    else:\n",
        "      tit=\"No Tumor\"\n",
        "    plt.title(tit)\n",
        "    plt.imshow(images[i].permute(1, 2, 0), cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.savefig('./test1.jpg')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9-w3BBrpvTh"
      },
      "source": [
        "## Train--ViT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4D6i-fS1Qkfq"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(4)\n",
        "epochs=10\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "tb_writer = SummaryWriter()\n",
        "\n",
        "PCAM_ViT_model = ViT(img_size=96,num_classes=2,patch_size=8,embed_dim=288,depth=3,num_heads=12,in_c=3).to(device)\n",
        "\n",
        "optimizer = optim.Adam(PCAM_ViT_model.parameters(), lr=0.0003,weight_decay=5E-5,amsgrad=True)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # train\n",
        "    train_loss, train_acc = train_one_epoch(model=PCAM_ViT_model,\n",
        "                                            optimizer=optimizer,\n",
        "                                            data_loader=PCAM_train_loader,\n",
        "                                            device=device,\n",
        "                                            epoch=epoch)\n",
        "\n",
        "\n",
        "    # validate\n",
        "    val_loss, val_acc = evaluate(model=PCAM_ViT_model,\n",
        "                                 data_loader=PCAM_val_loader,\n",
        "                                 device=device,\n",
        "                                 epoch=epoch)\n",
        "\n",
        "    tags = [\"train_loss\", \"train_acc\", \"val_loss\", \"val_acc\", \"learning_rate\"]\n",
        "    tb_writer.add_scalar(tags[0], train_loss, epoch)\n",
        "    tb_writer.add_scalar(tags[1], train_acc, epoch)\n",
        "    tb_writer.add_scalar(tags[2], val_loss, epoch)\n",
        "    tb_writer.add_scalar(tags[3], val_acc, epoch)\n",
        "    tb_writer.add_scalar(tags[4], optimizer.param_groups[0][\"lr\"], epoch)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2Pxa-LjHP5Z"
      },
      "outputs": [],
      "source": [
        "PCAM_ViT_loss={}\n",
        "PCAM_ViT_acc={}\n",
        "\n",
        "\n",
        "for i in range(5):\n",
        "  print(\"train\",i)\n",
        "  torch.manual_seed(i)\n",
        "  epochs=10\n",
        "\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  tb_writer = SummaryWriter()\n",
        "\n",
        "  model = ViT(img_size=96,num_classes=2,patch_size=8,embed_dim=288,depth=3,num_heads=12,in_c=3).to(device)\n",
        "\n",
        "  optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "  PCAM_ViT_loss[\"train_exp_\"+str(i)]=[]\n",
        "  PCAM_ViT_acc[\"train_exp_\"+str(i)]=[]\n",
        "  PCAM_ViT_loss[\"val_exp_\"+str(i)]=[]\n",
        "  PCAM_ViT_acc[\"val_exp_\"+str(i)]=[]\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "      # train\n",
        "      train_loss, train_acc= train_one_epoch(model=model,\n",
        "                                              optimizer=optimizer,\n",
        "                                              data_loader=PCAM_train_loader,\n",
        "                                              device=device,\n",
        "                                              epoch=epoch)\n",
        "\n",
        "      PCAM_ViT_loss[\"train_exp_\"+str(i)].append(train_loss)\n",
        "      PCAM_ViT_acc[\"train_exp_\"+str(i)].append(train_acc)\n",
        "      \n",
        "      # validate\n",
        "      val_loss, val_acc = evaluate(model=model,\n",
        "                                  data_loader=PCAM_val_loader,\n",
        "                                  device=device,\n",
        "                                  epoch=epoch)\n",
        "      end_time=time.time()\n",
        "      PCAM_ViT_loss[\"val_exp_\"+str(i)].append(val_loss)\n",
        "      PCAM_ViT_acc[\"val_exp_\"+str(i)].append(val_acc)\n",
        "      \n",
        "      tags = [\"train_loss\", \"train_acc\", \"val_loss\", \"val_acc\", \"learning_rate\"]\n",
        "      tb_writer.add_scalar(tags[0], train_loss, epoch)\n",
        "      tb_writer.add_scalar(tags[1], train_acc, epoch)\n",
        "      tb_writer.add_scalar(tags[2], val_loss, epoch)\n",
        "      tb_writer.add_scalar(tags[3], val_acc, epoch)\n",
        "      tb_writer.add_scalar(tags[4], optimizer.param_groups[0][\"lr\"], epoch)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5vhWTFiVH6sO"
      },
      "outputs": [],
      "source": [
        "#save the result\n",
        "\n",
        "PCAM_vit={\"PCAM_ViT_loss\":PCAM_ViT_loss,\"PCAM_ViT_acc\":PCAM_ViT_acc}\n",
        "PCAM_vit_js= json.dumps(PCAM_vit) \n",
        " \n",
        "PCAM_vit_fileObject = open('/content/drive/MyDrive/PCAM_vit2.json', 'w')\n",
        "PCAM_vit_fileObject.write(PCAM_vit_js)\n",
        "PCAM_vit_fileObject.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEl9eJy0p7AA"
      },
      "source": [
        "## hyperparameter optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rykihqGphrBY"
      },
      "outputs": [],
      "source": [
        "def PCAM_objective(trial):\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  epochs=10\n",
        "  lr=trial.suggest_float(\"LR\", 1e-4, 1e-2,log=True)\n",
        "  \n",
        "  patch_size=trial.suggest_categorical(\"Patch_Size\", [8,16,32])\n",
        "  embed_dim=trial.suggest_categorical(\"Hidden_Size\", [96,192,288,384,480])\n",
        "  depth=trial.suggest_categorical(\"Layers\", [3,6,9])\n",
        "  num_heads=trial.suggest_categorical(\"Heads\", [6,8,12])\n",
        "  \n",
        "  model = ViT(img_size=96,num_classes=2,patch_size=patch_size,embed_dim=embed_dim,depth=depth,num_heads=8,in_c=3).to(device)\n",
        "  print(\"patch_size\",patch_size,\"embed_dim\",embed_dim,\"depth\",depth,\"epochs\",epochs,\"lr\",lr)\n",
        "  optimizer = optim.Adam(model.parameters(),lr=lr,weight_decay=5E-5,amsgrad=True)\n",
        "  total_time=0\n",
        "  for epoch in range(epochs):\n",
        "      epoch_start_time=time.time()\n",
        "      train_loss, train_acc = train_one_epoch(model=model,\n",
        "                                              optimizer=optimizer,\n",
        "                                              data_loader=PCAM_train_loader,\n",
        "                                              device=device,\n",
        "                                              epoch=epoch)\n",
        "\n",
        "      val_loss, val_acc = evaluate(model=model,\n",
        "                                  data_loader=PCAM_val_loader,\n",
        "                                  device=device,\n",
        "                                  epoch=epoch)\n",
        "      \n",
        "      epoch_end_time=time.time()\n",
        "      epoch_time=epoch_end_time-epoch_start_time\n",
        "      total_time=total_time+epoch_time\n",
        "      trial.report(val_acc, epoch)\n",
        "      # Handle pruning based on the intermediate value.\n",
        "      if trial.should_prune():\n",
        "        raise optuna.exceptions.TrialPruned()\n",
        "      if epoch_time>600:\n",
        "        raise optuna.exceptions.TrialPruned()\n",
        "      if total_time>3800:\n",
        "        raise optuna.exceptions.TrialPruned()\n",
        "  return val_acc "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOeHou2gulTO"
      },
      "outputs": [],
      "source": [
        "optuna.logging.get_logger(\"optuna\").addHandler(logging.StreamHandler(sys.stdout))\n",
        "study_name = \"PCAM_ViT_study3\"\n",
        "storage_name = \"sqlite:////content/drive/MyDrive/{}.db\".format(study_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1PYi6HeHpgms"
      },
      "outputs": [],
      "source": [
        "PCAM_ViT_study = optuna.create_study(direction='maximize',study_name=study_name,storage=storage_name)\n",
        "PCAM_ViT_study.optimize(PCAM_objective, n_trials=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "PrQiXCwd9h8N",
        "outputId": "bc4f39b8-6197-436d-8dd1-b2aba3c770d9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"abd00cd3-745e-4da6-a93a-71a31af9f5a9\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"abd00cd3-745e-4da6-a93a-71a31af9f5a9\")) {                    Plotly.newPlot(                        \"abd00cd3-745e-4da6-a93a-71a31af9f5a9\",                        [{\"cliponaxis\":false,\"hovertemplate\":[\"num_heads (CategoricalDistribution): 0.02172129216340817<extra></extra>\",\"lr (LogUniformDistribution): 0.07671826220816272<extra></extra>\",\"depth (CategoricalDistribution): 0.11533966350528325<extra></extra>\",\"patch_size (CategoricalDistribution): 0.38816254954113616<extra></extra>\",\"embed_dim (CategoricalDistribution): 0.3980582325820097<extra></extra>\"],\"marker\":{\"color\":\"rgb(66,146,198)\"},\"orientation\":\"h\",\"text\":[\"0.02172129216340817\",\"0.07671826220816272\",\"0.11533966350528325\",\"0.38816254954113616\",\"0.3980582325820097\"],\"textposition\":\"outside\",\"texttemplate\":\"%{text:.2f}\",\"x\":[0.02172129216340817,0.07671826220816272,0.11533966350528325,0.38816254954113616,0.3980582325820097],\"y\":[\"num_heads\",\"lr\",\"depth\",\"patch_size\",\"embed_dim\"],\"type\":\"bar\"}],                        {\"showlegend\":false,\"title\":{\"text\":\"Hyperparameter Importances\"},\"xaxis\":{\"title\":{\"text\":\"Importance for Objective Value\"}},\"yaxis\":{\"title\":{\"text\":\"Hyperparameter\"}},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('abd00cd3-745e-4da6-a93a-71a31af9f5a9');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "optuna.visualization.plot_param_importances(PCAM_ViT_study)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CmTGrZue9oUk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "9382ff60-4e3c-4a80-d214-e86b1fa43de7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"c704f239-d0a6-4463-bef4-e9c8239c4a4b\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c704f239-d0a6-4463-bef4-e9c8239c4a4b\")) {                    Plotly.newPlot(                        \"c704f239-d0a6-4463-bef4-e9c8239c4a4b\",                        [{\"dimensions\":[{\"label\":\"Objective Value\",\"range\":[0.73760986328125,0.819000244140625],\"values\":[0.77032470703125,0.73760986328125,0.797637939453125,0.819000244140625,0.769744873046875,0.81634521484375,0.748992919921875,0.774932861328125,0.774658203125]},{\"label\":\"Heads\",\"range\":[0,1],\"ticktext\":[6,8],\"tickvals\":[0,1],\"values\":[0,0,0,1,1,1,1,1,1]},{\"label\":\"Hidden_Size\",\"range\":[0,3],\"ticktext\":[192,288,384,480],\"tickvals\":[0,1,2,3],\"values\":[1,2,3,0,0,0,1,2,3]},{\"label\":\"LR\",\"range\":[-3.939513180254329,-2.382269151774719],\"ticktext\":[\"0.000115\",\"0.001\",\"0.00415\"],\"tickvals\":[-3.939513180254329,-3,-2.382269151774719],\"values\":[-3.146517687904293,-2.398689145315749,-2.382269151774719,-3.4877973933143136,-3.939513180254329,-3.056843056095127,-3.1921955081895588,-3.5787745060687435,-2.965253666605926]},{\"label\":\"Layers\",\"range\":[0,2],\"ticktext\":[3,6,9],\"tickvals\":[0,1,2],\"values\":[2,1,0,0,0,1,0,0,0]},{\"label\":\"Patch_Size\",\"range\":[0,1],\"ticktext\":[8,16],\"tickvals\":[0,1],\"values\":[1,0,1,0,0,0,0,0,0]}],\"labelangle\":30,\"labelside\":\"bottom\",\"line\":{\"color\":[0.77032470703125,0.73760986328125,0.797637939453125,0.819000244140625,0.769744873046875,0.81634521484375,0.748992919921875,0.774932861328125,0.774658203125],\"colorbar\":{\"title\":{\"text\":\"Objective Value\"}},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"reversescale\":false,\"showscale\":true},\"type\":\"parcoords\"}],                        {\"title\":{\"text\":\"Parallel Coordinate Plot\"},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('c704f239-d0a6-4463-bef4-e9c8239c4a4b');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "optuna.visualization.plot_parallel_coordinate(study)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFtkNYCWCQvz"
      },
      "source": [
        "## Train--RseNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBIu_c06DAZn"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(4)\n",
        "\n",
        "epochs=10\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "tb_writer = SummaryWriter()\n",
        "\n",
        "PCAM_ResNet_model = MyResNet().to(device)\n",
        "\n",
        "\n",
        "optimizer = optim.Adam(PCAM_ResNet_model.parameters(), lr=0.0003,weight_decay=5E-5,amsgrad=True)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # train\n",
        "    train_loss, train_acc = train_one_epoch(model=PCAM_ResNet_model,\n",
        "                                            optimizer=optimizer,\n",
        "                                            data_loader=PCAM_train_loader,\n",
        "                                            device=device,\n",
        "                                            epoch=epoch)\n",
        "    # validate\n",
        "    val_loss, val_acc = evaluate(model=PCAM_ResNet_model,\n",
        "                                data_loader=PCAM_val_loader,\n",
        "                                device=device,\n",
        "                                epoch=epoch)\n",
        "\n",
        "    tags = [\"train_loss\", \"train_acc\", \"val_loss\", \"val_acc\", \"learning_rate\"]\n",
        "    tb_writer.add_scalar(tags[0], train_loss, epoch)\n",
        "    tb_writer.add_scalar(tags[1], train_acc, epoch)\n",
        "    tb_writer.add_scalar(tags[2], val_loss, epoch)\n",
        "    tb_writer.add_scalar(tags[3], val_acc, epoch)\n",
        "    tb_writer.add_scalar(tags[4], optimizer.param_groups[0][\"lr\"], epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlL4VuDJHa29"
      },
      "outputs": [],
      "source": [
        "PCAM_Res_loss={}\n",
        "PCAM_Res_acc={}\n",
        "\n",
        "\n",
        "for i in range(5):\n",
        "  print(\"train\",i)\n",
        "  torch.manual_seed(i)\n",
        "  epochs=10\n",
        "\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  tb_writer = SummaryWriter()\n",
        "\n",
        "  model = MyResNet().to(device)\n",
        "\n",
        "  optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
        "\n",
        "  PCAM_Res_loss[\"train_exp_\"+str(i)]=[]\n",
        "  PCAM_Res_acc[\"train_exp_\"+str(i)]=[]\n",
        "  PCAM_Res_loss[\"val_exp_\"+str(i)]=[]\n",
        "  PCAM_Res_acc[\"val_exp_\"+str(i)]=[]\n",
        "  for epoch in range(epochs):\n",
        "      # train\n",
        "      train_loss, train_acc= train_one_epoch(model=model,\n",
        "                                              optimizer=optimizer,\n",
        "                                              data_loader=PCAM_train_loader,\n",
        "                                              device=device,\n",
        "                                              epoch=epoch)\n",
        "\n",
        "      PCAM_Res_loss[\"train_exp_\"+str(i)].append(train_loss)\n",
        "      PCAM_Res_acc[\"train_exp_\"+str(i)].append(train_acc)\n",
        "      \n",
        "      # validate\n",
        "      val_loss, val_acc = evaluate(model=model,\n",
        "                                  data_loader=PCAM_val_loader,\n",
        "                                  device=device,\n",
        "                                  epoch=epoch)\n",
        "     \n",
        "      PCAM_Res_loss[\"val_exp_\"+str(i)].append(val_loss)\n",
        "      PCAM_Res_acc[\"val_exp_\"+str(i)].append(val_acc)\n",
        "      \n",
        "      tags = [\"train_loss\", \"train_acc\", \"val_loss\", \"val_acc\", \"learning_rate\"]\n",
        "      tb_writer.add_scalar(tags[0], train_loss, epoch)\n",
        "      tb_writer.add_scalar(tags[1], train_acc, epoch)\n",
        "      tb_writer.add_scalar(tags[2], val_loss, epoch)\n",
        "      tb_writer.add_scalar(tags[3], val_acc, epoch)\n",
        "      tb_writer.add_scalar(tags[4], optimizer.param_groups[0][\"lr\"], epoch)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0N74sqdKZYB"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "PCAM_res={\"PCAM_Res_loss\":PCAM_Res_loss,\"PCAM_Res_acc\":PCAM_Res_acc}\n",
        "PCAM_res_js= json.dumps(PCAM_res) \n",
        " \n",
        "PCAM_res_fileObject = open('/content/drive/MyDrive/PCAM_res.json', 'w')\n",
        "PCAM_res_fileObject.write(PCAM_res_js)\n",
        "PCAM_res_fileObject.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AmNmABHOOnP"
      },
      "source": [
        "# NCT-CRC-HE-100K"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDqhjtu2YV8W"
      },
      "source": [
        "## Dowload Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9pQqAOBN5Fwr"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/drive/MyDrive/data/NCT-CRC-HE-100K.zip ./NCT-CRC-HE-100K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrJaUAeoYbE9"
      },
      "outputs": [],
      "source": [
        "# !wget https://zenodo.org/record/1214456/files/NCT-CRC-HE-100K.zip?download=1\n",
        "!mv NCT-CRC-HE-100K NCT-CRC-HE-100K.zip\n",
        "!unzip -o -d ./ /content/NCT-CRC-HE-100K.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6C_IVAMHX3gX"
      },
      "source": [
        "## Get DataSet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9rlJ7XTOqtZ"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(4)\n",
        "data_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5])\n",
        "    ])\n",
        "\n",
        "\n",
        "all_dataset = torchvision.datasets.ImageFolder('./NCT-CRC-HE-100K', transform=data_transform)\n",
        "batch_size=10\n",
        "\n",
        "train_test_set,valid_set = torch.utils.data.random_split(dataset= all_dataset, lengths=[90000, 10000])\n",
        "train_set,test_set = torch.utils.data.random_split(dataset= train_test_set, lengths=[80000, 10000])\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "test_loader= torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xjlTs91WY6p5"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(5)\n",
        "images, labels = next(iter(train_loader))\n",
        "print(images.size())\n",
        "plt.figure(figsize=(9, 9))\n",
        "for i in range(9):\n",
        "    plt.subplot(3, 3, i+1)\n",
        "    img=images[i].permute(1, 2, 0)\n",
        "    \n",
        "    plt.imshow(torch.squeeze(img, dim=2), cmap='gray')\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TfnyBW8qdwp"
      },
      "source": [
        "## Train-ViT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HDMvjeqic1ep"
      },
      "outputs": [],
      "source": [
        "NCT_Vit_loss={}\n",
        "NCT_Vit_acc={}\n",
        "\n",
        "for i in range(5):\n",
        "  print(\"train\",i)\n",
        "  torch.manual_seed(i)\n",
        "  epochs=10\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  tb_writer = SummaryWriter()\n",
        "\n",
        "  NCT_ViT_model = ViT(img_size=224,num_classes=9,patch_size=16,embed_dim=192,depth=3,num_heads=12,in_c=3).to(device)\n",
        "\n",
        "  optimizer = optim.Adam(NCT_ViT_model.parameters(), lr=0.0003,weight_decay=5E-5,amsgrad=True)\n",
        "\n",
        "  NCT_Vit_loss[\"train_exp_\"+str(i)]=[]\n",
        "  NCT_Vit_acc[\"train_exp_\"+str(i)]=[]\n",
        "  NCT_Vit_loss[\"val_exp_\"+str(i)]=[]\n",
        "  NCT_Vit_acc[\"val_exp_\"+str(i)]=[]\n",
        "  for epoch in range(epochs):\n",
        "    # train\n",
        "    train_loss, train_acc = train_one_epoch(model=NCT_ViT_model,\n",
        "                                            optimizer=optimizer,\n",
        "                                            data_loader=train_loader,\n",
        "                                            device=device,\n",
        "                                            epoch=epoch)\n",
        "    NCT_Vit_loss[\"train_exp_\"+str(i)].append(train_loss)\n",
        "    NCT_Vit_acc[\"train_exp_\"+str(i)].append(train_acc)\n",
        "\n",
        "\n",
        "    # validate\n",
        "    val_loss, val_acc = evaluate(model=NCT_ViT_model,\n",
        "                                data_loader=valid_loader,\n",
        "                                device=device,\n",
        "                                epoch=epoch)\n",
        "\n",
        "    NCT_Vit_loss[\"val_exp_\"+str(i)].append(train_loss)\n",
        "    NCT_Vit_acc[\"val_exp_\"+str(i)].append(train_acc)\n",
        "\n",
        "    tags = [\"train_loss\", \"train_acc\", \"val_loss\", \"val_acc\", \"learning_rate\"]\n",
        "    tb_writer.add_scalar(tags[0], train_loss, epoch)\n",
        "    tb_writer.add_scalar(tags[1], train_acc, epoch)\n",
        "    tb_writer.add_scalar(tags[2], val_loss, epoch)\n",
        "    tb_writer.add_scalar(tags[3], val_acc, epoch)\n",
        "    tb_writer.add_scalar(tags[4], optimizer.param_groups[0][\"lr\"], epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FxF1wMgz4AC9"
      },
      "outputs": [],
      "source": [
        "NCT_Vit={\"NCT_Vit_loss\":NCT_Vit_loss,\"NCT_Vit_acc\":NCT_Vit_acc}\n",
        "NCT_Vit_js= json.dumps(NCT_Vit) \n",
        " \n",
        "NCT_Vit_fileObject = open('/content/drive/MyDrive/NCT_Vit.json', 'w')\n",
        "NCT_Vit_fileObject.write(NCT_Vit_js)\n",
        "NCT_Vit_fileObject.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUNnjD27Fp1D"
      },
      "source": [
        "## Train-ResNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XyMPrHnrFol2"
      },
      "outputs": [],
      "source": [
        "NCT_Res_loss={}\n",
        "NCT_Res_acc={}\n",
        "\n",
        "for i in range(5):\n",
        "  print(\"train\",i)\n",
        "  torch.manual_seed(i)\n",
        "  epochs=10\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  tb_writer = SummaryWriter()\n",
        "\n",
        "  NCT_ResNet_model = MyResNet().to(device)\n",
        "\n",
        "  optimizer = optim.Adam(NCT_ResNet_model.parameters(), lr=0.003)\n",
        "\n",
        "  NCT_Res_loss[\"train_exp_\"+str(i)]=[]\n",
        "  NCT_Res_acc[\"train_exp_\"+str(i)]=[]\n",
        "  NCT_Res_loss[\"val_exp_\"+str(i)]=[]\n",
        "  NCT_Res_acc[\"val_exp_\"+str(i)]=[]\n",
        "  for epoch in range(epochs):\n",
        "      # train\n",
        "      train_loss, train_acc = train_one_epoch(model=NCT_ResNet_model,\n",
        "                                              optimizer=optimizer,\n",
        "                                              data_loader=train_loader,\n",
        "                                              device=device,\n",
        "                                              epoch=epoch)\n",
        "      NCT_Res_loss[\"train_exp_\"+str(i)].append(train_loss)\n",
        "      NCT_Res_acc[\"train_exp_\"+str(i)].append(train_acc)\n",
        "\n",
        "\n",
        "      # validate\n",
        "      val_loss, val_acc = evaluate(model=NCT_ResNet_model,\n",
        "                                  data_loader=valid_loader,\n",
        "                                  device=device,\n",
        "                                  epoch=epoch)\n",
        "      NCT_Res_loss[\"val_exp_\"+str(i)].append(val_loss)\n",
        "      NCT_Res_acc[\"val_exp_\"+str(i)].append(val_acc)\n",
        "\n",
        "      tags = [\"train_loss\", \"train_acc\", \"val_loss\", \"val_acc\", \"learning_rate\"]\n",
        "      tb_writer.add_scalar(tags[0], train_loss, epoch)\n",
        "      tb_writer.add_scalar(tags[1], train_acc, epoch)\n",
        "      tb_writer.add_scalar(tags[2], val_loss, epoch)\n",
        "      tb_writer.add_scalar(tags[3], val_acc, epoch)\n",
        "      tb_writer.add_scalar(tags[4], optimizer.param_groups[0][\"lr\"], epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62cCtFMM7sFP"
      },
      "outputs": [],
      "source": [
        "NCT_res={\"NCT_Res_loss\":NCT_Res_loss,\"NCT_Res_acc\":NCT_Res_acc}\n",
        "NCT_res_js= json.dumps(NCT_res) \n",
        " \n",
        "NCT_res_fileObject = open('/content/drive/MyDrive/NCT_res.json', 'w')\n",
        "NCT_res_fileObject.write(NCT_res_js)\n",
        "NCT_res_fileObject.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uyzWOjnjXeI"
      },
      "source": [
        "## hyperparameter optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tctbLz8Sjfxq"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "\n",
        "\n",
        "def objective(trial):\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  epochs=10\n",
        "  lr=trial.suggest_float(\"lr\", 1e-4, 1e-2,log=True)\n",
        "  \n",
        "  patch_size=trial.suggest_categorical(\"Patch_Size\", [16,28,32])\n",
        "  embed_dim=trial.suggest_categorical(\"Hidden_Size\", [96,192,288,384,480])\n",
        "  depth=trial.suggest_categorical(\"Layers\", [3,6,9])\n",
        "  num_heads=trial.suggest_categorical(\"Heads\", [6,8,12])\n",
        "\n",
        "  model = ViT(img_size=224,num_classes=9,patch_size=patch_size,embed_dim=embed_dim,depth=depth,num_heads=num_heads,in_c=3).to(device)\n",
        "\n",
        "  print(\"patch_size\",patch_size,\"embed_dim\",embed_dim,\"depth\",depth,\"epochs\",epochs,\"lr\",lr)\n",
        "  optimizer = optim.Adam(model.parameters(),lr=lr,weight_decay=5E-5,amsgrad=True)\n",
        "  total_time=0\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "      epoch_start_time=time.time()\n",
        "      train_loss, train_acc = train_one_epoch(model=model,\n",
        "                                              optimizer=optimizer,\n",
        "                                              data_loader=train_loader,\n",
        "                                              device=device,\n",
        "                                              epoch=epoch)\n",
        "\n",
        "      val_loss, val_acc = evaluate(model=model,\n",
        "                                  data_loader=valid_loader,\n",
        "                                  device=device,\n",
        "                                  epoch=epoch)\n",
        "      \n",
        "      epoch_end_time=time.time()\n",
        "      epoch_time=epoch_end_time-epoch_start_time\n",
        "      total_time=total_time+epoch_time\n",
        "      trial.report(val_acc, epoch)\n",
        "      # Handle pruning based on the intermediate value.\n",
        "      if trial.should_prune():\n",
        "        raise optuna.exceptions.TrialPruned()\n",
        "      if epoch_time>720:\n",
        "        raise optuna.exceptions.TrialPruned()\n",
        "      if total_time>3800:\n",
        "        raise optuna.exceptions.TrialPruned()\n",
        "  return val_acc "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bF_kHqC_Bc9W"
      },
      "outputs": [],
      "source": [
        "optuna.logging.get_logger(\"optuna\").addHandler(logging.StreamHandler(sys.stdout))\n",
        "study_name = \"NCT_ViT_study\"\n",
        "storage_name = \"sqlite:////content/drive/MyDrive/{}.db\".format(study_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IAiL6Wc5kuXO"
      },
      "outputs": [],
      "source": [
        "study = optuna.create_study(direction='maximize',study_name=study_name,storage=storage_name)\n",
        "study.optimize(objective, n_trials=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8KdF_i2On6ew"
      },
      "outputs": [],
      "source": [
        "optuna.visualization.plot_parallel_coordinate(study) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fSNj7GrJnvX"
      },
      "outputs": [],
      "source": [
        "optuna.visualization.plot_param_importances(study)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reOoSo-IQPQa"
      },
      "source": [
        "# Data show"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j80jXMQfnMx9"
      },
      "source": [
        "## tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpcqXXQXWXEa"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDXcBEurU9oz"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir=runs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_a8LPgWoYOR"
      },
      "source": [
        "## Mean, Variance and Standard deviation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sE8ph8p8oXCW"
      },
      "outputs": [],
      "source": [
        "arr =[95.26,96.44,97.43,95.72,96.95]\n",
        " \n",
        "# Mean\n",
        "arr_mean = np.mean(arr)\n",
        " \n",
        "# Variance\n",
        "arr_var = np.var(arr)\n",
        " \n",
        "# Standard deviation\n",
        "arr_std = np.std(arr)\n",
        " \n",
        " \n",
        "print(\"Mean:%f\" % arr_mean)\n",
        "print(\"Variance:%f\" % arr_var)\n",
        "print(\"Standard deviation:%f\" % arr_std)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZXXxJ5indt7"
      },
      "source": [
        "## T-test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKuAIke5FR-F"
      },
      "outputs": [],
      "source": [
        "from scipy import stats\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "\n",
        "Sample_A = [79.92,74.59,78.39,77.29,75.63]\n",
        "Sample_B = [79.48,78.45,82.64,79.77,82.36]\n",
        "\n",
        "\n",
        "_, levene_p = stats.levene(Sample_A, Sample_B)\n",
        "print(f\"levene_p = {levene_p}\")\n",
        "\n",
        "# = 0.05\n",
        "if levene_p > 0.05: \n",
        "    t, p = ttest_ind(Sample_A, Sample_B, equal_var=True)\n",
        "else:\n",
        "    t, p = ttest_ind(Sample_A, Sample_B, equal_var=False)\n",
        "\n",
        "print(f\"t = {t}, p = {p}\")\n",
        "if p<0.05:\n",
        "    print(\"The difference is statistically significant\")\n",
        "else:\n",
        "    print(\"The difference is not statistically significant\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwaKCCX2qEoK"
      },
      "source": [
        "## The images of experiments using different hyperparameters on the Mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HRakQ15p8ra"
      },
      "outputs": [],
      "source": [
        "result_json=[\"diff_Hidden_Size\",\"diff_Layers\",\"diff_lr\",\"diff_num_heads\",\"diff_patch_size\"]\n",
        "for doc in result_json:\n",
        "  with open('/content/drive/MyDrive/'+doc+'.json', mode='r') as f:\n",
        "      dicts = json.load(f)\n",
        "\n",
        "  fig=plt.figure(figsize=(16,6)) \n",
        "\n",
        "  ax1 = fig.add_subplot(121)\n",
        "  ax1.set_xlabel('Epoch(times)',fontsize=14)\n",
        "  ax1.set_ylabel('Loss',fontsize=16)\n",
        "  title_loss=\"Different \"+doc[5:].title()+\" Loss\"\n",
        "  ax1.set_title(title_loss,fontsize=14)\n",
        "\n",
        "  ax2 = fig.add_subplot(122)\n",
        "  ax2.set_xlabel('Epoch(times)',fontsize=14)\n",
        "  ax2.set_ylabel('Accuracy',fontsize=16)\n",
        "  title_acc=\"Different \"+doc[5:].title()+\" Accuracy\"\n",
        "  ax2.set_title(title_acc,fontsize=14)\n",
        "\n",
        "\n",
        "  for dict_ in dicts:\n",
        "    if str(dict_).endswith(\"train_loss\"):\n",
        "      for i in dicts[str(dict_)]:\n",
        "        ax1.plot(dicts[str(dict_)][i],label=i)\n",
        "    if str(dict_).endswith(\"val_acc\"):\n",
        "      for i in dicts[str(dict_)]:\n",
        "        ax2.plot(dicts[str(dict_)][i],label=i)\n",
        "  ax1.set_yticks(np.arange(0.6,2),minor=True)\n",
        "  ax2.set_yticks(np.arange(0,1),minor=True)\n",
        "\n",
        "  ax1.set_xticks(np.arange(0,21,2))\n",
        "  ax2.set_xticks(np.arange(0,21,2))\n",
        "\n",
        "  ax2.legend(loc='best')\n",
        "  ax1.legend(loc='best')\n",
        "  title_='Different '+doc[5:].title()+' on MNIST'\n",
        "  plt.suptitle(title_,fontsize=18)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The images of experiments using different hyperparameters on the CIFAR-10"
      ],
      "metadata": {
        "id": "W9rpSZc3vmDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result_json=[\"CIR_diff_Hidden_Size\",\"CIF_diff_Layers\",\"CIF_diff_LR\",\"CIF_diff_num_heads\",\"CIF_diff_patch_size\"]\n",
        "for doc in result_json:\n",
        "  with open('/content/drive/MyDrive/'+doc+'.json', mode='r') as f:\n",
        "      dicts = json.load(f)\n",
        "\n",
        "  fig=plt.figure(figsize=(16,6)) \n",
        "\n",
        "  ax1 = fig.add_subplot(121)\n",
        "  ax1.set_xlabel('Epoch(times)',fontsize=14)\n",
        "  ax1.set_ylabel('Loss',fontsize=16)\n",
        "  title_loss=\"Different \"+doc[9:].title()+\" Loss\"\n",
        "  ax1.set_title(title_loss,fontsize=14)\n",
        "\n",
        "  ax2 = fig.add_subplot(122)\n",
        "  ax2.set_xlabel('Epoch(times)',fontsize=14)\n",
        "  ax2.set_ylabel('Accuracy',fontsize=16)\n",
        "  title_acc=\"Different \"+doc[9:].title()+\" Accuracy\"\n",
        "  ax2.set_title(title_acc,fontsize=14)\n",
        "\n",
        "\n",
        "  for dict_ in dicts:\n",
        "    if str(dict_).endswith(\"train_loss\"):\n",
        "      for i in dicts[str(dict_)]:\n",
        "        ax1.plot(dicts[str(dict_)][i],label=i)\n",
        "    if str(dict_).endswith(\"val_acc\"):\n",
        "      for i in dicts[str(dict_)]:\n",
        "        ax2.plot(dicts[str(dict_)][i],label=i)\n",
        "  ax1.set_yticks(np.arange(0.5,2),minor=True)\n",
        "  ax2.set_yticks(np.arange(0,1),minor=True)\n",
        "\n",
        "  ax1.set_xticks(np.arange(0,21,2))\n",
        "  ax2.set_xticks(np.arange(0,21,2))\n",
        "\n",
        "  ax2.legend(loc='best')\n",
        "  ax1.legend(loc='best')\n",
        "  title_='Different '+doc[9:].title()+\" on CIFAR-10\"\n",
        "  plt.suptitle(title_,fontsize=18)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "neKpo4FzvrqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQQmktwJqvT2"
      },
      "source": [
        "## Results of five experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vn9fKcdgsbCN"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "from scipy.ndimage import gaussian_filter1d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RA2S8FjLquqt"
      },
      "outputs": [],
      "source": [
        "def loss_acc_img(dicts):\n",
        "  n=list(dicts[0].keys())[0][:5]\n",
        "  if n==\"Mnist\":\n",
        "    xticks_range=21\n",
        "  else:\n",
        "    xticks_range=11\n",
        "\n",
        "  fig=plt.figure(figsize=(16,6)) \n",
        "\n",
        "  ax1 = fig.add_subplot(121)\n",
        "  ax1.set_xlabel('Epoch(times)',fontsize=14)\n",
        "  ax1.set_ylabel('Loss',fontsize=16)\n",
        "  ax1.set_title(\"Loss\",fontsize=14)\n",
        "\n",
        "\n",
        "  ax2 = fig.add_subplot(122)\n",
        "  ax2.set_xlabel('Epoch(times)',fontsize=14)\n",
        "  ax2.set_ylabel('Accuracy',fontsize=16)\n",
        "  ax2.set_title(\"Accuracy\",fontsize=14)\n",
        "\n",
        "  for dataset_dicts in dicts:\n",
        "    for dataset_dict in dataset_dicts:\n",
        "      dict_=dataset_dicts[dataset_dict]\n",
        "      \n",
        "      a=dataset_dict[-4:]\n",
        "      if dataset_dicts==dicts[0]:\n",
        "        label=\"ViT\"\n",
        "        color=\"#EF8636\"\n",
        "      else:\n",
        "        label=\"ResNet\"\n",
        "        color=\"#3B75AF\"\n",
        "      label_show=True\n",
        "      for i,exp in enumerate(dict_):\n",
        "\n",
        "        if a==\"loss\":\n",
        "          if exp[:5]==\"train\":\n",
        "            ax1.plot(preprocessing.minmax_scale(dict_[str(exp)]),alpha = 0.7,color=color,label=label if i==0 else None )\n",
        "        else:\n",
        "          if exp[:3]==\"val\":\n",
        "            ax2.plot(gaussian_filter1d(dict_[str(exp)], sigma=2),color=color,label=label if label_show else None )\n",
        "            label_show=False\n",
        "\n",
        "  ax1.set_yticks(np.arange(0,1),minor=True)\n",
        "  ax2.set_yticks(np.arange(0.9,1),minor=True)\n",
        "  ax1.grid(ls=':', color='gray', alpha=0.3)\n",
        "  ax2.grid(ls=':', color='gray', alpha=0.3)\n",
        "  ax1.set_xticks(np.arange(0,xticks_range,2))\n",
        "  ax2.set_xticks(np.arange(0,xticks_range,2))\n",
        "\n",
        "\n",
        "  ax2.legend(loc='best')\n",
        "  ax1.legend(loc='best')\n",
        "  plt.suptitle('',fontsize=18)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S42g6GBhxOwZ"
      },
      "source": [
        "### Mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43wTzNNdx52k"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/mnist_vit.json', mode='r') as f:\n",
        "    mnist_vit_dicts = json.load(f)\n",
        "\n",
        "with open('/content/drive/MyDrive/mnist_res.json', mode='r') as f:\n",
        "    mnist_res_dicts = json.load(f)\n",
        "\n",
        "dicts=[mnist_vit_dicts,mnist_res_dicts]\n",
        "\n",
        "loss_acc_img(dicts)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CIFAR-10"
      ],
      "metadata": {
        "id": "wrk5MtIXwFOU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/CIF_vit.json', mode='r') as f:\n",
        "    CIF_vit_dicts = json.load(f)\n",
        "\n",
        "with open('/content/drive/MyDrive/CIF_res.json', mode='r') as f:\n",
        "    CIF_res_dicts = json.load(f)\n",
        "\n",
        "dicts=[CIF_vit_dicts,CIF_res_dicts]\n",
        "\n",
        "loss_acc_img(dicts)"
      ],
      "metadata": {
        "id": "LQN7__0rwEo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlI3mdBUxMNG"
      },
      "source": [
        "### 100K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ivg_gNF_xbVF"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/NCT_Vit.json', mode='r') as f:\n",
        "    NCT_Vit_dicts = json.load(f)\n",
        "\n",
        "with open('/content/drive/MyDrive/NCT_res.json', mode='r') as f:\n",
        "    NCT_res_dicts = json.load(f)\n",
        "\n",
        "dicts=[NCT_Vit_dicts,NCT_res_dicts]\n",
        "\n",
        "loss_acc_img(dicts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPIQiBIrxCbL"
      },
      "source": [
        "### PCAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dr018nfMrrFx"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/PCAM_vit.json', mode='r') as f:\n",
        "    PCAM_vit_dicts = json.load(f)\n",
        "\n",
        "with open('/content/drive/MyDrive/PCAM_res.json', mode='r') as f:\n",
        "    PCAM_res_dicts = json.load(f)\n",
        "\n",
        "dicts=[PCAM_vit_dicts,PCAM_res_dicts]\n",
        "loss_acc_img(dicts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kg0_NjcXJ4rx"
      },
      "source": [
        "# CKA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WYHv38SdjmfO"
      },
      "outputs": [],
      "source": [
        "from torch_cka import CKA\n",
        "\n",
        "def CKA_image(model_ViT,model_Res,dataset,device,Dataset_name):\n",
        "  cka1 = CKA(model_ViT, model_ViT,\n",
        "          model1_name=\"ViT\",   \n",
        "          model2_name=\"ViT\",   \n",
        "          device=device)\n",
        "\n",
        "  cka1.compare(dataset) \n",
        "\n",
        "  results1 = cka1.export() \n",
        "  save_path=\"/content/drive/MyDrive/ViT-ViT_compare_\"+Dataset_name+\".png\"\n",
        "  cka1.plot_results(save_path=save_path)\n",
        "\n",
        "  cka2 = CKA(model_Res, model_Res,\n",
        "          model1_name=\"ResNet\",   \n",
        "          model2_name=\"ResNet\",   \n",
        "          device=device)\n",
        "\n",
        "  cka2.compare(dataset) \n",
        "\n",
        "  results2 = cka2.export() \n",
        "  save_path=\"/content/drive/MyDrive/Res-Res_compare_\"+Dataset_name+\".png\"\n",
        "  cka2.plot_results(save_path=save_path)\n",
        "\n",
        "  cka3 = CKA(model_ViT, model_Res,\n",
        "          model1_name=\"ViT\",   \n",
        "          model2_name=\"ResNet\",   \n",
        "          device=device)\n",
        "\n",
        "  cka3.compare(dataset) \n",
        "\n",
        "  results3 = cka3.export() \n",
        "  save_path=\"/content/drive/MyDrive/ViT-Res_compare_\"+Dataset_name+\".png\"\n",
        "  cka3.plot_results(save_path=save_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CIFAR-10"
      ],
      "metadata": {
        "id": "3FgnInp-xqze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "CKA_image(CIF_vit_model,CIF_res_model,CIF_testloader,device,\"CIF\")"
      ],
      "metadata": {
        "id": "iBMcI5dgxljV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PCAM"
      ],
      "metadata": {
        "id": "NrVUyixWx2CJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "CKA_image(PCAM_ViT_model,PCAM_ResNet_model,PCAM_val_loader,device,\"PCAM\")"
      ],
      "metadata": {
        "id": "nNF8MS6hx5UZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 100K"
      ],
      "metadata": {
        "id": "oUdEYmxdxxop"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "CKA_image(NCT_ViT_model, NCT_ResNet_model,valid_loader,device,\"100k\")"
      ],
      "metadata": {
        "id": "slw9zwN_xl92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlEJoVXeXss6"
      },
      "source": [
        "# Release GPU memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQ4JOx6SXuQ7",
        "outputId": "4d33b7af-e5a9-46b9-ea4b-97f9e6effbc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/dev/nvidia0:         2726m\n",
            "/dev/nvidiactl:       2726m\n",
            "/dev/nvidia-uvm:      2726m\n"
          ]
        }
      ],
      "source": [
        "!sudo fuser /dev/nvidia*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GeVFMary__WE"
      },
      "outputs": [],
      "source": [
        "!kill -9 2726"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SelFAxfVYDUZ"
      },
      "source": [
        "# Calculating model parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-q227sfaf5k"
      },
      "outputs": [],
      "source": [
        " model = ViT(img_size=224,num_classes=9,patch_size=16,embed_dim=192,depth=3,num_heads=8,in_c=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bf9QOwYhYFhY"
      },
      "outputs": [],
      "source": [
        "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "pytorch_total_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2X5n2LAuuI9k"
      },
      "outputs": [],
      "source": [
        "model = MyResNet()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLDHnXyRuJDF"
      },
      "outputs": [],
      "source": [
        "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "pytorch_total_params"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "UJseRZw9aRUt"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1_tQgLhhgizJ2g8P-uxS6BNwVpyd07LNS",
      "authorship_tag": "ABX9TyNbvic1qHdliSyrpTYV21zs",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}